{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Fp3R2ICNTkT"
      },
      "source": [
        "# Assignment 3: Transformers\n",
        "\n",
        "In this homework, we will practise using the **ðŸ¤— Hugging Face** libraries for transformers and datasets for natural language processing. Follow the directions in each section to complete the expected parts. Take into account the following guidelines:\n",
        "\n",
        "*   **Assignment Due Date:** <b><font color='red'>1401.03.09</font></b> 23:59:00\n",
        "*   We always recommend co-operation and discussion in groups for assignments. However, each student has to finish all the questions by him/herself. If our matching system identifies any sort of copying, you'll be responsible for consequences.\n",
        "\n",
        "*   The items you need to answer are highlighted in bold SeaGreen and the coding parts you need to implement are denoted by:\n",
        "```\n",
        "#######################\n",
        "# Your implementation #\n",
        "#######################\n",
        "```\n",
        "*   If you have any issues about this assignment, please do not hesitate to contact us. But before, check the provided documentation links for Hugging Face and PyTorch first.\n",
        "*   This code requires some of the dependencies of the COLAB platform, you are free to use any other platform that supports jupyter notebooks, but there is no guarantee that the code snippets will work in your setting without some modifications. \n",
        "*   You can double click on collapsed code cells to expand them.\n",
        "*   <b><font color='red'>When you are ready to submit, please follow the instructions at the end of this notebook.</font></b>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRnFoPPtVMZk",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Import and Install Essential Packages\n",
        "\n",
        "%pip install transformers tokenizers datasets\n",
        "\n",
        "# Enable the following line if you want to see error stack in GPU mode\n",
        "# %env CUDA_LAUNCH_BLOCKING=1\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "clear_output()\n",
        "print(\"Done!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WomGhk_sYQFZ"
      },
      "source": [
        "## Part 1: Take advantage of Transformers power"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35CAIylRfWO0"
      },
      "source": [
        "Previously, you solved the SNLI dataset with recurrent neural networks, which is a popular dataset for natural language inference. In this part, you will fine-tune a transformer encoder only model to utilize in the same dataset and task. \n",
        "\n",
        "In order to complete this section:\n",
        "*   You should follow each steps below and compelete each block.\n",
        "*   Run the model for **at least** one epoch.\n",
        "*   Evaluate your model on the **test set** using accuracy metrics **at least after each 5000 optimization steps**.\n",
        "\n",
        "Hints: \n",
        "*   You can import the dataset using any technique that works best for you, although the SNLI dataset is available in the Hugging Face hub, and you can find instructions for loading the dataset using the `datasets` library [here](https://huggingface.co/datasets/snli).\n",
        "*   If your code's runtime exceeds one hour, you can downscale the training corpus using `datasets.train_test_split` method.\n",
        "*   You can use any strategy to fine-tune the model in this case, however we recommend using Trainer API because it will make your life easier.\n",
        "*   You may also find the [Practical NLP Tutorial Notebooks](https://teias-courses.github.io/nlp00/schedule), which are available on the course schedule page, particularly useful in completing this section."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Arguments\n",
        "model_name = \"roberta-base\" #@param {type:\"string\"}\n",
        "max_sequence_length = 256 #@param {type:\"integer\"}\n",
        "output_directory = \"roberta-snli-finetuned\" #@param {type:\"string\"}\n",
        "per_device_train_batch_size =  64#@param {type:\"integer\"}\n",
        "per_device_eval_batch_size =  64#@param {type:\"integer\"}\n",
        "learning_rate = 5e-5 #@param {type:\"number\"}\n",
        "num_train_epochs = 2 #@param {type:\"integer\"}\n",
        "evaluation_strategy = \"steps\" #@param {type:\"string\"}\n",
        "logging_steps =  5000#@param {type:\"integer\"}\n"
      ],
      "metadata": {
        "id": "pnPd_I7NTkp_",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9bG2vdU2P98"
      },
      "outputs": [],
      "source": [
        "#@title Import Packages\n",
        "\n",
        "#######################\n",
        "# Your implementation #\n",
        "#######################\n",
        "\n",
        "\n",
        "clear_output()\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZPlVlSIz6F9"
      },
      "outputs": [],
      "source": [
        "#@title Load the Dataset\n",
        "\n",
        "#######################\n",
        "# Your implementation #\n",
        "#######################\n",
        "\n",
        "\n",
        "clear_output()\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJgvoXx20Efw"
      },
      "outputs": [],
      "source": [
        "#@title Load the Model\n",
        "\n",
        "#######################\n",
        "# Your implementation #\n",
        "#######################\n",
        "\n",
        "\n",
        "clear_output()\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHYOT4UE1mLu"
      },
      "outputs": [],
      "source": [
        "#@title Tokenization\n",
        "\n",
        "#######################\n",
        "# Your implementation #\n",
        "#######################\n",
        "\n",
        "\n",
        "clear_output()\n",
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_400l9hRTPSf"
      },
      "outputs": [],
      "source": [
        "#@title Compute Metrics\n",
        "def compute_metrics(eval_preds):\n",
        "    #######################\n",
        "    # Your implementation #\n",
        "    #######################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7dK0bLJ8Zli"
      },
      "outputs": [],
      "source": [
        "#@title Training Arguments\n",
        "\n",
        "#######################\n",
        "# Your implementation #\n",
        "#######################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HfxG2VFq3rsD"
      },
      "outputs": [],
      "source": [
        "#@title Train the Model\n",
        "\n",
        "#######################\n",
        "# Your implementation #\n",
        "#######################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXo7Qdt_HM3X"
      },
      "outputs": [],
      "source": [
        "#@title Plot the Confusion Matrix on Test Set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PK9qch2nKnhh"
      },
      "source": [
        "Answer the following questions:\n",
        "\n",
        "\n",
        "1. Plot the confusion matrix. Compare the results to those of your prior RNN-based models.\n",
        "\n",
        "2. On the plot, analyze the model output. Where does the model perform badly? \n",
        "\n",
        "2. Explain the reasons you think why the model performs poorly in this area.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer The Question Here**"
      ],
      "metadata": {
        "id": "iDMOMKW8cjpb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM7mmWjI_4u5"
      },
      "source": [
        "## Part 2: Custom Loss Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTvnanO-F_is"
      },
      "source": [
        "When employing transformers (especially in research), it is usual to desire to tweak some aspects of the model's functionality. Suppose that the default Cross Entropy Loss does not work good in your settings. You may consider using the Focal Loss. Focal loss applies a modulating term to the cross entropy loss in order to focus learning on hard misclassified examples. \n",
        "\n",
        "Formally, the Focal Loss adds a factor $(1-p)^{\\gamma}$ to the standard cross entropy criterion. Setting $\\gamma > 0$ reduces the relative loss for well-classified examples ($p_t > 0.5$), putting more focus on hard, misclassified examples.\n",
        "\n",
        "\\begin{equation}\n",
        "F L(p) = -\\alpha (1-p)^{\\gamma} \\log (p)\n",
        "\\end{equation}\n",
        "\n",
        "In order to complete this section:\n",
        "\n",
        "- Complete the following loss function. You can use the sanity check block to compare your answer to ours.\n",
        "- Change the training pipeline to use your custom loss function instead of the cross entropy.\n",
        "\n",
        "Hints:\n",
        "- Understanding the `tensor.gather` operand will probably reduce the amount of code you write."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIeekrNT8irJ"
      },
      "outputs": [],
      "source": [
        "#@title Custom Loss Function Implementation\n",
        "def focal_loss(logits, labels, alpha=1.0, gamma=2):\n",
        "  #######################\n",
        "  # Your implementation #\n",
        "  #######################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjTYXnOYR4zn",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Loss Function Sanity Check\n",
        "labels = torch.tensor([0, 1, 2, 1, 2])\n",
        "logits = torch.tensor([[1., 0, 0],\n",
        "                       [1., 0, 0],\n",
        "                       [0, 0, 1.],\n",
        "                       [1., 0, 0],\n",
        "                       [0, 0, 1.]])\n",
        "loss = focal_loss(logits, labels)\n",
        "assert (torch.abs(loss - 0.449) < 0.01), \"Wrong implementation. Correct: {}. Yours: {}\".format(0.449, loss) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dpwbod1CIkp"
      },
      "outputs": [],
      "source": [
        "#@title Using the Custom Function in Your Training Pipeline\n",
        "\n",
        "#######################\n",
        "# Your implementation #\n",
        "#######################\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCszAitAHLTI"
      },
      "outputs": [],
      "source": [
        "#@title Traing the Model\n",
        "\n",
        "#######################\n",
        "# Your implementation #\n",
        "#######################\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot the Confusion Matrix on Test Set\n"
      ],
      "metadata": {
        "id": "4nOUULqzbXnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer the following questions:\n",
        "\n",
        "1. Plot the confusion matrix and compare the results with previous section.\n",
        "\n",
        "2. What areas does the new model perform better (or worse) in, and why?"
      ],
      "metadata": {
        "id": "AvN0qM7GbQ8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer The Question Here**"
      ],
      "metadata": {
        "id": "wDoLa469ceW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Model Analysis and Interpretation"
      ],
      "metadata": {
        "id": "ZV89ikNUVqm2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you are familiar with fine-tuning transformer models and have gotten acceptable results using a transformer model. It is time to interpret our model. We can look at a transformer as a black box function, which takes an input in the form of string(s), and outputs a probability based on the application of the function on the input. As models increase in complexity, it gets more difficult to correctly pinpoint the reason behind their behavior. However, it is paramount to strive to understand this, as models often perform in unexpected ways, which might jeopardize our intent for using them. \n",
        "\n",
        "As a starting point in model analysis, we will look into [Erasure](https://arxiv.org/pdf/1612.08220.pdf). Erasure is an early, yet effective method to find the sections of input that contribute to the model output, enabling us to pinpoint the tokens that effective determine model behavior. \n",
        "\n",
        "For this task, we will implement a simplified version of Erasure using our previous transformer model fine-tuned on the SNLI task. "
      ],
      "metadata": {
        "id": "gmv79UAHV1aq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To ease your work, we are going to give you a step by step instruction in implementing Erasure. Read the steps below carefully as you are required to implement them. \n",
        "\n",
        "\n",
        "\n",
        "1.   Prepare two inputs for the SNLI task. (Example: \"He is a firefighter\" and \"He has worked in the same department for 20 years\"). \n",
        "2.   Feed your inputs to your fine-tuned transformer model and document the probability of one of the outputs. (Example: Label: 1, Probability: 0.76)\n",
        "3.   Perturb your input by looping over tokens in each sentence, in each step, remove one of the tokens, feed the new perturbed inputs to the model, and document the probability change in the most probable output. \n",
        "4.   The change in probability is the contribution of that token on the model output. \n",
        "\n",
        "Note that contribution can either be negative or positive. With negative contribution indicating that the word actually lowers the probability of an output.\n",
        "\n",
        "With these information in mind, write your code below. \n",
        "\n"
      ],
      "metadata": {
        "id": "7Lah5UEIY_mT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compute token importances towards predicting a target word\n",
        "def compute_importances(text1,text2, target_label_index=0):\n",
        "  \"\"\"\n",
        "  Computes importance scores for tokens in the input texts (premise and hypothesis). The target model is assumed to\n",
        "  be gloabl. If you want to change the function signature and pass the model as argument,\n",
        "  remember to fix the function calls in the visulization cells bellow.\n",
        "\n",
        "  Args:\n",
        "    text1: raw text, premise of the SNLI task\n",
        "    text2: raw text, hypothesis of the SNLI task\n",
        "    target_label_index: the rank of target label in the top predictions (i-th most probable label)\n",
        "\n",
        "  Returns:\n",
        "    tokens: tokenized input texts, concatenated. (list of str)\n",
        "    importances: list of importance values for each token. (length = length of tokens)\n",
        "\n",
        "  \"\"\"\n",
        "  #######################\n",
        "  # Your implementation #\n",
        "  #######################\n",
        "\n",
        "  return tokens, importances"
      ],
      "metadata": {
        "id": "ZvY43qrjfQSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great job, now that you have written a function that computes importances, it is time to do an initial testing on it. To ease your work, we provide a function for visualizing the importances."
      ],
      "metadata": {
        "id": "DwwgZPB7gapR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Visualize importance\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.colors as clr\n",
        "from pylab import rcParams\n",
        "\n",
        "from IPython.display import HTML\n",
        "\n",
        "def visualize_attention(sentences, score_lists, color_maps='RdYlGn', rtl=False,\n",
        "                        alpha=0.5, font_size=14, token_sep=' ', sentence_sep='<br/><br/>'):\n",
        "\n",
        "  if type(color_maps) is str:\n",
        "    color_maps = [color_maps] * len(sentences)\n",
        "\n",
        "  span_sentences, style_sentences = [], []\n",
        "\n",
        "  for s, tokens in enumerate(sentences):\n",
        "\n",
        "    scores = score_lists[s]\n",
        "    cmap = cm.get_cmap(color_maps[s])\n",
        "    \n",
        "    max_value = max(abs(min(scores)), abs(max(scores)))\n",
        "    normer = clr.Normalize(vmin=-max_value/alpha, vmax=max_value/alpha)\n",
        "    colors = [clr.to_hex(cmap(normer(x))) for x in scores]\n",
        "\n",
        "    if len(tokens) != len(colors):\n",
        "        raise ValueError(\"number of tokens and colors don't match\")\n",
        "\n",
        "    style_elems, span_elems = [], []\n",
        "    for i in range(len(tokens)):\n",
        "        style_elems.append(f'.c{s}-{i} {{ background-color: {colors[i]}; }}')\n",
        "        span_elems.append(f'<span class=\"c{s}-{i}\">{tokens[i]} </span>')\n",
        "\n",
        "    span_sentences.append(token_sep.join(span_elems))\n",
        "    style_sentences.append(' '.join(style_elems))\n",
        "    text_dir = 'rtl' if rtl else 'ltr'\n",
        "\n",
        "  return HTML(f\"\"\"<html><head><link href=\"https://fonts.googleapis.com/css?family=Roboto+Mono&display=swap\" rel=\"stylesheet\">\n",
        "               <style>span {{ font-family: \"Roboto Mono\", monospace; font-size: {font_size}px; padding: 2px}} {' '.join(style_sentences)}</style>\n",
        "               </head><body><p dir=\"{text_dir}\">{sentence_sep.join(span_sentences)}</p></body></html>\"\"\")"
      ],
      "metadata": {
        "id": "8v5Z_GggmMhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test your code by running the code below. "
      ],
      "metadata": {
        "id": "bGGSkQBopY_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Implementation verification\n",
        "\n",
        "\n",
        "# @title visualize importance\n",
        "\n",
        "colormap = \"RdYlGn\" #@param [\"RdYlGn\", \"bwr_r\"]\n",
        "alpha = 0.8 #@param {type:\"number\"}\n",
        "right_to_left = False #@param {type:\"boolean\"}\n",
        "\n",
        "your_tokens, your_importances = compute_importances('My brother plays football.','But my sister prefers basketball.', 0)\n",
        "display(visualize_attention([your_tokens], [your_importances], color_maps=colormap, rtl=right_to_left, alpha=alpha))"
      ],
      "metadata": {
        "id": "iWjMGInBm9Rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great job, now that we have all our tools ready, lets run some tests and answer some questions. Run the code below to visualize your answers."
      ],
      "metadata": {
        "id": "UeU6y6wPoUWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Visualize importances\n",
        "\n",
        "premise = \"Football is the most popular sport in the world.\" #@param {type:\"string\"}\n",
        "hypothesis = \"Basketball is the most watched sport in the world\" #@param (type:\"string\")\n",
        "target_label_index = 0 #@param {type:\"integer\"}\n",
        "\n",
        "colormap = \"RdYlGn\" #@param [\"RdYlGn\", \"bwr_r\"]\n",
        "alpha = 0.8 #@param {type:\"number\"}\n",
        "right_to_left = False #@param {type:\"boolean\"}\n",
        "\n",
        "tokens, importances = compute_importances(premise, hypothesis, target_label_index)\n",
        "display(visualize_attention([tokens], [importances], color_maps=colormap, rtl=right_to_left, alpha=alpha))"
      ],
      "metadata": {
        "id": "h3rfWHhHohsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Having visualized the example (Or any other example that you wish), answer the questions below. \n",
        "\n",
        "\n",
        "\n",
        "1.   What words have the highest impact on the output of the model? (Either positive or negative). For the top 3 words with the highest impact, explain why you think this is the case.\n",
        "2.   Are there any words that you think should have had higher impacts? If so, explain why you think this is the case. If you can't find any, feel free to change the example and find the said words in another example, but make sure to mention the example too. \n",
        "\n"
      ],
      "metadata": {
        "id": "JtlVgrCLqBmv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Type Your Answer Here**"
      ],
      "metadata": {
        "id": "tlLuaBqMreO4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Having seen a few examples and their analysis, lets think about this method more broadly. Answer the questions below. \n",
        "\n",
        "\n",
        "\n",
        "1.   Using the toolset above, find an example that yields counter intuitive results. For example, it pays attention to words that you would normally not to, or does not pay attention to words that you think are important. This might take a bit of testing to find. Provide your example here, explain why you think this is the case, are there any other words in the example that you think might be taking the attention away from the important words?\n",
        "2.   Having thought about the previous question, what do you think are the shortcomings of this method? Hint: Think about independence and Hindsight Bias.\n",
        "\n",
        "3.   How do you think the aforementioned shortcomings can be addressed? Hint: Think about methods that don't require erasing a token. Explain your answer in detail. \n",
        "\n"
      ],
      "metadata": {
        "id": "1Wiypy0Nrm1z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Type Your Answer Here**"
      ],
      "metadata": {
        "id": "28fV2fDawnKz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Few-Shot Learning"
      ],
      "metadata": {
        "id": "kNR9hBhSwQTU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a real life setting, it is often the case that we don't have access to a large enough data that correctly corresponds with the classes that we might see during inference time. This is when Few-Shot-Learning (FSL) comes in. FSL basically consists of training the model on a small sample of classes during training using various techniques such that the model can generalize them to inference. \n",
        "\n",
        "In this part of your homework, we are going to implement two simple few-shot-learner model to get you acquainted with how it works. "
      ],
      "metadata": {
        "id": "Bm47jdIqwXXs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Few-Shot Learning With the Custom Loss\n",
        "\n",
        "A common approach to do Few-Shot Learning is to define a new loss function such that the given loss function has an excellent generalization capabilities. Focal Loss, as explained above, is a great choice when we either have class imbalance or a low number of samples for each class. Thus, we are going to use a model that utilizes focal loss in this section. \n",
        "\n",
        "First, we need change our data such that there are only a handful of samples for each class. Additionally, we are going to make our classes imbalanced and see how the focal loss performs. \n",
        "\n",
        "To start, complete the function below such that given a dataset (or Pandas, this is your choice) instance of SNLI, the dataset is reduced such that 100 examples of class 0, 100 examples of class 1, and 32 examples of class 2 remains. This will make sure that your dataset is both in a few-shot setting and is also imbalanced. "
      ],
      "metadata": {
        "id": "JDVFS3EP5sbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reduce_dataset(dataset, class_0 = 100 , class_1 = 100, class_2 = 16) :\n",
        "  ######################\n",
        "  #Implement your Code Here\n",
        "  ######################\n",
        "  return reduced_dataset\n",
        "\n",
        "######################\n",
        "#Test your function Here \n",
        "######################"
      ],
      "metadata": {
        "id": "0lDnYCKt9-oM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great, now that you have redcued our dataset, lets see if a model can learn from this.\n",
        "Write a code below such that an instance of a normal Roberta or Bert is initialized, trained using focal loss, and tested on the test set of SNLI. \n",
        "\n",
        "Note that this is not much different from Part 3, thus feel free to copy your code from there if you find that easier. "
      ],
      "metadata": {
        "id": "GxUQ4MBO-v_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######################\n",
        "#Implement your Code Here\n",
        "######################"
      ],
      "metadata": {
        "id": "K1x6BlRM_ef7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Good job, now that you have trained and tested your model (only on a handful of data), we can observe how our model performs in a low-shot setting with imbalanced data.\n",
        "\n",
        "First, draw a confusion matrix for the performance of our current model for better analysis of the two models."
      ],
      "metadata": {
        "id": "z_SjduDN_pxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######################\n",
        "#Implement your Code Here\n",
        "######################"
      ],
      "metadata": {
        "id": "f5gqPS4g_pQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now answer the questions below.\n",
        "\n",
        "\n",
        "\n",
        "1.   Which class performs the worst? Which class performs the best? What do you think is the reason behind this?\n",
        "2.   Compare the performances of the model trained using the few-shot setting and the model trained earlier. Which model performs better? Does the other model perform reasonably well too? \n",
        "3.   How do you think the focal loss helps with imbalanced data and few-shot learning? \n",
        "\n"
      ],
      "metadata": {
        "id": "WSdxcKROATZ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer The Questions Here**"
      ],
      "metadata": {
        "id": "pm3lOkQFBAAu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transfer Learning\n",
        "\n",
        "Another approach for few shot (and zero shot) learning is to make use of another model, previously trained on a similar task (such as a clssification task that is close to our current task), and briefly fine-tuning it to cater to our needs. \n",
        "\n",
        "In this section, we are going to make use of this. The tasks you have to conduct are as following. \n",
        "\n",
        "\n",
        "\n",
        "1.   Go to [Hugging Face Hub](https://huggingface.co/models) and identify a model pre-trained/fine-tuned on a task that is similar to our current task. Needless to say, this task can't be SNLI itself as we are trying to do few-shot learning.\n",
        "2.   Load the model that you have identified.\n",
        "3.   Fine tune the model with the proportion Class 0 = 100, Class 1 = 100, Class 2 = 100. \n",
        "4.   Test the model\n",
        "\n",
        "Hint: Make sure that the classifier header either fits, or you change it. Look at how pipeline classification works so you can get a better understanding on how to formulate this problem.\n",
        "\n"
      ],
      "metadata": {
        "id": "nykV_sdeBXNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######################\n",
        "#Implement your Code Here\n",
        "######################"
      ],
      "metadata": {
        "id": "VUD3GQtWSJ6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Good job. Now that you have trained, and tested this new approach, answer the questions below. \n",
        "\n",
        "\n",
        "\n",
        "1.   Explain how do you think your chosen model and the task that it is trained on is similar to our current task?\n",
        "2.   How do you think the fact above helps the model geranlize? \n",
        "3.   Compare the transfer learning model and direct fine tuning model in terms of performance, which model performs better? What do you think is the reason behind this? \n",
        "4.   Note that the two approaches stated here are very simple methods to do few-shot learning and may not work as well. What do you think are some other methods to apply few shot learning to NLP tasks? Name and explain at least 2 other models. Google is your friend on this one. \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZWWh7nCCSP5w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer The Question Here**"
      ],
      "metadata": {
        "id": "HfNHn08OTUe4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fill Your Information"
      ],
      "metadata": {
        "id": "7C4n5eImehaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Enter your information & \"RUN the cell!!\" { run: \"auto\" }\n",
        "student_id = \"\" #@param {type:\"string\"}\n",
        "student_name = \"\" #@param {type:\"string\"}\n",
        "\n",
        "print(\"your student id:\", student_id)\n",
        "print(\"your name:\", student_name)\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "ASSIGNMENT_PATH = Path('asg04')\n",
        "ASSIGNMENT_PATH.mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Hj8rqiuFejDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make Submission (Run the cells)"
      ],
      "metadata": {
        "id": "qvqmpXimc7AO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Make submission\n",
        "! pip install -U --quiet PyDrive > /dev/null\n",
        "! pip install -U --quiet jdatetime > /dev/null\n",
        "\n",
        "# ! wget -q https://github.com/github/hub/releases/download/v2.10.0/hub-linux-amd64-2.10.0.tgz \n",
        "\n",
        "\n",
        "import os\n",
        "import time\n",
        "import yaml\n",
        "import json\n",
        "import jdatetime\n",
        "\n",
        "from google.colab import files\n",
        "from IPython.display import Javascript\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "asg_name = 'NLP_Assignment_3_Transformers'\n",
        "script_save = '''\n",
        "require([\"base/js/namespace\"],function(Jupyter) {\n",
        "    Jupyter.notebook.save_checkpoint();\n",
        "});\n",
        "'''\n",
        "# repo_name = 'iust-deep-learning-assignments'\n",
        "submission_file_name = 'nlp_asg03__%s__%s.zip'%(student_id, student_name.lower().replace(' ',  '_'))\n",
        "\n",
        "sub_info = {\n",
        "    'student_id': student_id,\n",
        "    'student_name': student_name, \n",
        "    'dateime': str(jdatetime.date.today()),\n",
        "    'asg_name': asg_name\n",
        "}\n",
        "json.dump(sub_info, open('info.json', 'w'))\n",
        "\n",
        "Javascript(script_save)\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "file_id = drive.ListFile({'q':\"title='%s.ipynb'\"%asg_name}).GetList()[0]['id']\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('%s.ipynb'%asg_name) \n",
        "\n",
        "! jupyter nbconvert --to script \"$asg_name\".ipynb > /dev/null\n",
        "! jupyter nbconvert --to html \"$asg_name\".ipynb > /dev/null\n",
        "! zip \"$submission_file_name\" \"$asg_name\".ipynb \"$asg_name\".html \"$asg_name\".txt info.json > /dev/null\n",
        "\n",
        "print(\"##########################################\")\n",
        "print(\"Done! Submisson created, Please download using the bellow cell!\")"
      ],
      "metadata": {
        "id": "e1vHmry9dBc1",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.ListFile({'q':\"title='%s.ipynb'\"%asg_name}).GetList()[0]['id']"
      ],
      "metadata": {
        "id": "zJAEq8HGdDmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(submission_file_name)"
      ],
      "metadata": {
        "id": "X6jb8yQBdEcO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "aM7mmWjI_4u5"
      ],
      "name": "NLP_Assignment_3_Transformers.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}