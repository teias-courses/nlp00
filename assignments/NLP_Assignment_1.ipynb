{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wb32bya7A08w"
      },
      "source": [
        "# Homework 1\n",
        "\n",
        "**Due date: Sunday, Esfand 24th, 23:59**\n",
        "\n",
        "In this homework, we are going to have a bit of fun with word embeddings. We will see their usage, and develop our own Word Embeddings too.\n",
        "\n",
        "You are free to discuss the problems and ways to approach them with your classmates, but be sure to not cheat. **Cheating will not be tolerated.**\n",
        "\n",
        "This code requires some of the dependencies of the COLAB platform, you are free to use any other platform that supports jupyter notebooks, but there is no guarantee that the code snippets will work in your setting without some modifications. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vis0w0GXB0Mt"
      },
      "source": [
        "## Import the Required Libraries\n",
        "\n",
        "Feel free to use any other library to your heart's content (unless specified by the question), but give a link to its documentations if it is not a well known one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMxAtOtDAm5V"
      },
      "outputs": [],
      "source": [
        "import nltk \n",
        "import sklearn as sk\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import tensorflow as tf\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhgalvhuEUd9"
      },
      "source": [
        "## Get the Data Ready\n",
        "\n",
        "For this homework, we are going to use the Sentiment 140 dataset. This is a dataset containing almost 160,000 tweets from twitter.\n",
        "\n",
        "To make your work easier, we download and load a portion of the dataset for you.\n",
        "\n",
        "Run the cells below to download and extract the dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnbT-DxYHu7o"
      },
      "outputs": [],
      "source": [
        "!wget http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip\n",
        "!unzip trainingandtestdata.zip -d /content/Data\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYiiTE0XJHMP"
      },
      "source": [
        "Run the cell below to prepare the data as a pandas dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXU0xhVpJNLW"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/content/Data/training.1600000.processed.noemoticon.csv', header = None, encoding = \"ISO-8859-1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rdMdUXpKqIW"
      },
      "source": [
        "Run the cell below to \n",
        "\n",
        "\n",
        "1.   Convert the text and the labels to numpy arrays\n",
        "2.   Convert the labels to numeral integers\n",
        "3.   Take only 40,000 of the data for easier processing\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxqiMKBDK4sv"
      },
      "outputs": [],
      "source": [
        "data  = data.sample(frac = 0.25)\n",
        "text_data = list(data[5])\n",
        "label_list = list(data[0])\n",
        "text_data = np.array(text_data)\n",
        "label_list = np.array(label_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGJGPCjfk7a9"
      },
      "source": [
        "Now that we have loaded the data, we can start the fun part :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUTUMjXilKli"
      },
      "source": [
        "## Exercise 1: Statistical Word Embeddings\n",
        "\n",
        "In this exercise, we are going to attempt to make our very own word-embedding. Specifically, we will construct a co-occurrence word embedding. A co-occurrence word embedding is a type of word embedding in which for $N$ words, an $N \\times N$ matrix is created with $n_{i,j}$ determining the number of times the word in position $i$ appears adjacent to the word in position $j$. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2QvN8O3iCar"
      },
      "source": [
        "### 1.1. Cleaning the dataset\n",
        "First, in order to have a better performing model, we should clean our sentences as much as we can. This usually boils down to removing the punctuations, and uppercase words. \n",
        "\n",
        "Complete the function below such that given a numpy array (or list) of sentences, it returns another list of sentences such that the returned list has its punctuations removed, HTML tags removed, links removed, and upper case words converted to lower case. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RczkOHxDizZn"
      },
      "outputs": [],
      "source": [
        "def clean_sentences(list_of_sentences) : \n",
        "  #cleaned_sentences = ?  Write your code here\n",
        "  return cleaned_sentences\n",
        "#Give an example here that showcases the result of your code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzSVI7xpjX_x"
      },
      "source": [
        "Intuitively explain the reason behind removing the punctuations and converting the upper case words to lower case. What happens if we don't? Are there cases where it is better to leave the sentences as they are instead of attempting to clean them? \n",
        "\n",
        "Explain in terms of both the co-occurrence word embeddings and in a more general setting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEAVo0xtj3tx"
      },
      "source": [
        "Type your answer here: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMYguzm7fkw2"
      },
      "source": [
        "### 1.2. Word Tokenization\n",
        "\n",
        "in order to construct our word embedding, we need to tokenize the sentences. You will later use this function to tokenize the sentences of the dataset.\n",
        "\n",
        "Complete the below function such that given a numpy array (or list) of sentences, it returns a list of lists where each list corresponds with a sentence and each element of it is a tokenized word. \n",
        "\n",
        "Example: Suppose that you you have the list [\"i love natural language processing\", \"i love cats\"]. Given this list, your function should return [[\"i\",\"love\",\"natural\",\"language\",\"processing\"][\"i\",\"love\",\"cats\"]]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAra18Gjn6V2"
      },
      "outputs": [],
      "source": [
        "def tokenizer(list_of_sentences) : \n",
        "  #tokenized_sentences = ? Write your code here\n",
        "  return tokenized_sentences\n",
        "#Give an example here that showcases the result of your code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-nR46Lvq4re"
      },
      "source": [
        "### 1.3. Word  Vectorization\n",
        "Machine learning algorithms usually don't understand words in the string format. So it is better to convert the strings into a numeral format. While it is possible to construct a co-occurrence based  word embedding wihtout this step, it is far easier to just vectorize our words now rather than later as it is far easier to manipulate integers. \n",
        "\n",
        "Complete the function below such that given a numpy array (or a list) of tokenized sentences (list of lists), a mapping is created between the words and a numeric value. \n",
        "\n",
        "Example: Suppose that your sentences contain the words \"i\", \"love\", and \"cats\", what you want to do is to create a dictionary such that {\"i\" : 0, \"love\" : 1, \"cats\" : 2}. Having this knowledge, apply this to the entire dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5speZVaueU9"
      },
      "outputs": [],
      "source": [
        "def sentences_to_mapping(tokenized_sentences)  : \n",
        "  mapping = {}\n",
        "  #mapping = ? Write your code here\n",
        "  return mapping\n",
        "#Give an example here that showcases the result of your code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BG1YCEb7vEYV"
      },
      "source": [
        "Good job :). now that we have managed to create a mapping between each word and a numeric value, we should be able to vectorize our sentences, that is, replace the words in the tokenized sentences with their numeric value. \n",
        "\n",
        "Complete the function below such that given a list of tokenized sentences and a mapping that maps each word to a numeric value, another list of tokenized sentences is returned such that each word is replaced with their numeric  value. \n",
        "\n",
        "Example: Suppose that we have [[\"i\", \"love\", \"Cats\"]], and {\"i\" : 0, \"love\" : 1, \"cats\" : 2}, your function should return [[0,1,2]]. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLleOQpywtE9"
      },
      "outputs": [],
      "source": [
        "def transform_vectorize(tokenized_sentences, mapping) : \n",
        "  #vectorized_sentences = ? Write your code here\n",
        "  return vectorized_sentences\n",
        "#Give an example here that showcases the result of your code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcOjplAvxGsT"
      },
      "source": [
        "### 1.4. Constructing the Word Embeddings\n",
        "\n",
        "Now that we have all the tools we need for cleaning, tokenizing, and vectorizing our data, we can actually create the word embedding that we want. \n",
        "\n",
        "Complete the function below such that given a vectorized list of sentences, and a window that determines the number of words to look at in each direction, returns an $N \\times N$ matrix such that $N$ is the number of words in our vocabulary and $n_{i,j}$ is the number of times the word in poistion $i$, appears adjacent to the word in position $j$. \n",
        "\n",
        "Example: Suppose that we have the vectorized sentences [[0,1,2]], and window of 2. Our function should create the following $3 \\times   3$ matrix.\n",
        "\n",
        "![Matrix_Picture.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAEsAAACECAYAAADY8NaLAAADNUlEQVR4Xu2dMXLbMBBFqVLnUasiTS6Ug/hCaVLoTioTYxJOFJsk/iMIWPE8VZnJBxf79hNcguT4dL/ff06df68xOkeYpvP53D3GSVg5Y2HlrCZhEViXy6X7mgXm89TS7s66Xq/T7XbrCmFEjJKAsEAZhSUsQABIdZawAAEg1VnCAgSAVGcJCxAAUp0lLEAASHWWsAABIK06q9zRl9/enYN0RyDVLeWWjk11a/w2YT0efG+g2ri5GD0LckSMzS2apSRriX9U1dN5pTrsLGG9R7Z6GgpLWLsvVK5ZoG0QlrDWCXS7GpaQI/qsObWWRNKxqQ63Do9J9GwY56LM8fbcKSQQjmhMq7c78LR+J08S+R9ibC7wrQkccXqlcxhREGGl1fij8zQEwIQlLEAASHWWsAABINVZwgIEgFRnCQsQAFKdJSxAAEh1FoHlRwM5rSHO+vH9JZ/RDuWXr9+antqkIYWVknrVCUtYgACQ6ixhAQJAqrOEBQgAqc4SFiAApDpLWIAAkOosYQECQBo5q+XFizK2tutQdg3Kr6ZbyyvddWjJo8SufjQwT3DPe1NlbA1WSXSG9PhvUPCpBuuId7OqsOYJt1RkC9YSnD3AarCOyENYxL610/CIiugsUBFhCWudgAv8bzYf2md5NXxj0Gfos464UEXOam3oarDKJEZ08K15RLDAWr4oTWC1xkib0tY40ZrVEkRYgJ6whAUIAKnOEhYgAKQ6S1iAAJDqLGEBAkCqs4QFCACpzhIWIACkn8pZfjSQV37IFs3ep9lpGi3PCNIYwzb/hBWWZETVR8TQWWHBZ5lrFgAmLGEBAkCqs4QFCACpzhIWIACkOktYgACQ6qyjYbXce6VjU91SbsnY+ZWjlpv6IR8NbE3wiPemarAe/7+m3TJadBq2BEjHpjrqrKXj7o0lLNesvwR01hs3bJ1WwhLW/j+hrLPAwiusg2CVwwzrs1qbxqSnGRmjWwcPirsqTWC1xhkRw0dhsEpRBw+P+Y98RNVHxNBZ0AU6CwATlrAAASDVWcICBIBUZwkLEABSnSUsQABIdZawAAEgPfnRQE6r+2mYT+X5lcICNRKWsAABIP0FrI5PP+//VhYAAAAASUVORK5CYII=)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUK8F8G72CMI"
      },
      "outputs": [],
      "source": [
        "def cons_word_embedding(vectorized_sentences, window = 2) : \n",
        "  #co_occurrence_matrix = ? Write your code here\n",
        "  return co_occurrence_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMet-MVu39DW"
      },
      "source": [
        "Now that we have written the function, lets run our data through your pipeline and create the word embedding, you are free to make very small detail modifications to the code below, but **don't** change the overall structure. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0Q5Io4r4W0f"
      },
      "outputs": [],
      "source": [
        "cleaned_text_data = clean_sentences(text_data)\n",
        "tokenized_sentences = tokenizer(cleaned_text_data)\n",
        "mapping = sentences_to_mapping(tokenized_sentences)\n",
        "vectorized_sentences = transform_vectorize(tokenized_sentences, mapping)\n",
        "co_occurrence_word_embedding = cons_word_embedding(vectorized_sentences, window = 2)\n",
        "print(co_occurrence_word_embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNu_GZEn9tAR"
      },
      "source": [
        "### 1.5. Analyzing the Word Embeddings\n",
        "Now that we have constructed our word embedding, it is time to analyze our construct. Answer the questions below\n",
        "\n",
        "\n",
        "\n",
        "1.   Compare this approach to other methods such as TF-IDF and Deep Learning based Word Embeddings, how are they different? what are the advantages and the disadvantages of each approach?\n",
        "2.   How would you handle Out-of-Vocabulary words in this approach? Give 2 solutions and discuss their feasibility as well as their advantages and disadvantages.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0vBQacO__GZ"
      },
      "source": [
        "Type Your Answer Here: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRlG0BC1BaVi"
      },
      "source": [
        "## Exercise 2: Correcting the Statistical Word Embedding\n",
        "So far, we have managed to create our own word embedding, good job :). In this part, we are going to discuss the shortcomings of our current approach and try to ameliorate it with some simple solutsions. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSH6GPoICHiH"
      },
      "source": [
        "### 2.1. Problems with the Current Word Embedding \n",
        "\n",
        "Answer the questions below \n",
        "\n",
        "1 - Note that right now, each embedding of an arbitrary word is $N$ dimensional. Discuss why this can be a problem? Does an arbitrarily large word embedding result in better model performance? Discuss your answer and mention why you think your answer is the case. \n",
        "\n",
        "2 - Suppose that you have created a word embedding $W$ matrix from an arbitrary dataset. You now wish to use your dataset in a real Deep Learning model. Is it a good idea to further train your statistical word embedding in a downstream Deep Learning task? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE5cfYtrGuCR"
      },
      "source": [
        "Type your Answer Here: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPr5KQ7kGy2_"
      },
      "source": [
        "### 2.2. Dimension Reduction \n",
        "\n",
        "In this question, we wish to reduce the dimensionality of our word embeddings such that they are more in line with modern word embeddings. \n",
        "\n",
        "Complete the function below such that given a word embedding of size $N \\times N$, a word embedding of size $N \\times X$ is returned with $X < N$. \n",
        "\n",
        "Hint: For this purpose, explore  PCA and TruncatedSVD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnDAM4ceJFd4"
      },
      "outputs": [],
      "source": [
        "def reduce_dimension(embeddings, x = 64) : \n",
        "  #reduced_embeddings = ? Write your code here\n",
        "  return reduced_embeddings\n",
        "#Give an example here that showcases the result of your code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBXYeDSQNfb4"
      },
      "source": [
        "### 2.3. Visualizing the word embeddings  \n",
        "\n",
        "Remember that a good word embedding is a one that carries the meanings of the words in itself. Here, we want to visualize the word embedding that have created and analyze the spatial positions of each word. \n",
        "\n",
        "Complete the function below such that given a word embedding matrix, the data points are plotted in a 2D space. \n",
        "\n",
        "Hint: You have to use the \"reduce_dimension\" function to draw and the mapping that we created in the previous question to understand the mapping between data points and words. \n",
        "\n",
        "Your final plot should be similar to this plot. \n",
        "\n",
        "![Word_Embeddings.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Kc6emnAQRaz"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt \n",
        "def plot_embeddings(word_embeddings) : \n",
        "  #plot your embeddings here\n",
        "plot_embeddings(co_occurrence_word_embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zln8VmXQRAp7"
      },
      "source": [
        "Having visualized our word embedding, it is easier to analyze its properties and talk about its qualities. \n",
        "\n",
        "Answer the questions below based on your plot. \n",
        "\n",
        "\n",
        "\n",
        "1.   What words are clustered together? What words are not? give 3 pairs of words that you think are correctly clustered together and 3 pairs of words that you think should be clustered together but are not.\n",
        "2.   Why do you think some related words are not clustered together? How do you think we can solve this problem?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJ5dIVkZ0w-8"
      },
      "source": [
        "Type your Answer Here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QejFnh7Xc-Qo"
      },
      "source": [
        "## Exercise 3: Bias in Word Embeddings\n",
        "\n",
        "We have learned in the class that word embeddings might have social biases in them. That is, the embeddings of the words might carry biases from real life (they might have sexist, racist, and stereotypical implications). \n",
        "\n",
        "In this exercise, we will try to see these biases with our own eyes, first in Word2Vec embeddings, and then in the word embedding that we have created ourselves. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUSg3lM0kDdb"
      },
      "source": [
        "### 3.1. Bias in Glove\n",
        "\n",
        "We first start by having some fun with Glove embeddings and trying to find the bias in the embeddings. \n",
        "\n",
        "To start off, run the code below to load the embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uslyahlAkU6K"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api\n",
        "from gensim.models import Word2Vec\n",
        "word_vectors = api.load('glove-wiki-gigaword-100')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXu-o9VNlxQj"
      },
      "source": [
        "Now that we have loaded the embeddings, run the code below to see an example of the bias. To this end, we will make use of the analogy task, that is, we ask our model the following question: \n",
        "\n",
        "X to Y is like Z to what? \n",
        "\n",
        "If you are not familiar with this task, feel free to google it. It is a well known that and you must use it in this question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCqlnaOgl7LB",
        "outputId": "652e95fe-0ef0-4f6d-f152-e6d528848af2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "technician: 0.6620\n"
          ]
        }
      ],
      "source": [
        "result = word_vectors.most_similar(positive=['engineer', 'woman'], negative=['man'])\n",
        "most_similar_key, similarity = result[0]\n",
        "print(f\"{most_similar_key}: {similarity:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngDQmZthqoxI"
      },
      "source": [
        "Observe that the Glove word embeddings associate the word \"woman\" with \"technician\" when asked the question \n",
        "\n",
        "man to engineer is like woman to what? \n",
        "\n",
        "This is a blatant example of gender bias. In an ideal world, we would expect the model to make no association between the gender and the job, returning engineer instead. \n",
        "\n",
        "Having this knowledge,  answer the following questions: \n",
        "\n",
        "\n",
        "\n",
        "1.   Find 6 triplets of words for which you believe a form of bias is observable. You may use the code snippet above and replace the words with your own. Make sure that your answer contains both the analogy question as well as the answer, and the form of bias that you think is blatant.\n",
        "2.   What do you think the reason behind this bias is? Propose a method by which you think we can mitigate this bias. Explain your answer in detail.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2Hqdc8RsZzY"
      },
      "source": [
        "Type Your Answer Here: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXw70OZcsj8b"
      },
      "source": [
        "###  3.2. Bias in Our Own Word Embedding\n",
        "\n",
        "Now that we have observed the bias in a more common word embedding, lets see if we can find any social biases in our own word embedding. \n",
        "\n",
        "Complete the function below such that given a word embedding, a triplet of words, and a mapping of words, the function returns the 5 most probable answers in the format {word : probability score}. \n",
        "\n",
        "Hint: You have to use the word embedding that we have created, the mapping that we created, and a similarity metric to find the words that are most probable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMTqeBRBugJE"
      },
      "outputs": [],
      "source": [
        "def analogy(embedding, word_1, word_2, word_3, mapping) :\n",
        "  most_similar = {}\n",
        "  #most_similar = ? Write your code here \n",
        "  return most_similar\n",
        "#Give an example here that showcases the result of your code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu-eTnfKut8k"
      },
      "source": [
        "Good job, you have now made your own analogy function. \n",
        "With this function at hand, answer the following questions: \n",
        "\n",
        "\n",
        "\n",
        "1.   Can you find 3 triplets of words in our own word embedding for which a blatant bias is observable? If yes, write the question, the answer, and the type of the bias that you think is observable. If not, explain the reason why our word embedding has no such biases? \n",
        "2.   Name 2 more tasks by which we can understand if our model is biased, explain why you think these tasks are a good fit for understanding the bias in models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pB7tpKevw8wc"
      },
      "source": [
        "Type Your Answer Here: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8x3cfj562-17"
      },
      "source": [
        "## Exercise 4: Using the Word Embeddings\n",
        "\n",
        "In this exercise, we are going to directly use what we have learned so far in the classroom and through this homework. More precisely, we are going to try and develop a model that makes use of a word embedding to make its predictions.\n",
        "\n",
        "To start, we download and do an initial preprocessing on the SMSSPAMCollection dataset, which contains around 6000 samples tagged either as \"ham\" (or 0) and \"spam\" (1). \n",
        "Run the cell below to download the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgJxxpeN4oLu"
      },
      "outputs": [],
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\n",
        "!unzip smsspamcollection.zip -d /content/Data\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Onvww49a47bs"
      },
      "source": [
        "Now that we have downloaded the dataset, lets load it into a dataframe using pandas. Run the cell below to do that. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6JMbieo5GtL"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/content/Data/SMSSpamCollection', sep = '\\t', header = None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBsRIBKX5NQs"
      },
      "source": [
        "Great, we have now loaded the dataset as a pandas dataframe. Note that our labels are in the string format, we don't want that. Run the cell below to \n",
        "\n",
        "\n",
        "1.   Return the text and the labels as numpy arrays\n",
        "2.   Convert the labels to the integer format\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Y3eusTz53NL"
      },
      "outputs": [],
      "source": [
        "text_data = list(data[1])\n",
        "def str_label_to_num(label_list, label_0) : \n",
        "  '''\n",
        "  label_list = the list of labels that you have\n",
        "  label_0 = the label (in the string format) that you want to convert into the integer 0\n",
        "  '''\n",
        "  labels_in_num = []\n",
        "  for i in label_list : \n",
        "    if i == label_0 : \n",
        "      labels_in_num.append(0)\n",
        "    else : \n",
        "      labels_in_num.append(1)\n",
        "  return labels_in_num\n",
        "label_list = list(data[0])\n",
        "label_list = str_label_to_num(label_list, 'ham')\n",
        "text_data = np.array(text_data)\n",
        "label_list = np.array(label_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YRhsBgh33L2"
      },
      "source": [
        "### 4.1. Readying the Data for Training\n",
        "\n",
        "Now that we have loaded the data, we need to ready it for the training process. \n",
        "\n",
        "\n",
        "Using the functions that we determined in the first exercise, clean the data (text_data), and tokenize it to a list of lists with each word tokenized. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ergB76cRIlyr"
      },
      "outputs": [],
      "source": [
        "# Write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYzWOKw-IZud"
      },
      "source": [
        "Good job :). Now, we need to split the data so we can use it both for training and testing. \n",
        "\n",
        "Complete the function below such that given two lists (or numpy arrays), It splits the data into training and test sets, with training set being 80% of the entire data set and test set being 20% of the entire dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiOrHhfVHrrU"
      },
      "outputs": [],
      "source": [
        "def split(text_data,label_list) : \n",
        "  #Write your code below\n",
        "  #train_text = ?\n",
        "  #test_text = ?\n",
        "  #train_labels = ?\n",
        "  #test_labels = ? \n",
        "  return train_text, test_text, train_labels, test_labels \n",
        "train_text, test_text, train_labels, test_labels = split(text_data,label_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kfnn9c1pJW7L"
      },
      "source": [
        "Great, now we have out data cleaned, tokenized, and split into two sets that we can use for training and testing. Let's get to work. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6nzLo0PJiVl"
      },
      "source": [
        "### 4.2 Utilizing our Word Embedding\n",
        "\n",
        "The ultimate goal of a word embedding is to ease the training process by providing meaningful representations of the words to our model. At this stage, we will attempt to develop a model using the word embedding that we made. \n",
        "\n",
        "To start, we need to vectorize our dataset, and create a mapping just like we did before. \n",
        "\n",
        "Write a code below such that for our new dataset, a word mapping dictionary is created, mapping each word in the dataset to an integer. Then, vectorize the sentences, replacing each word with the corresponding integer. \n",
        "\n",
        "Hint: The mapping dictionary must be shared between train, and test sets. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AUT3MF2MuYp"
      },
      "outputs": [],
      "source": [
        "mapping = {}\n",
        "train_text_vectorized = np.array([])\n",
        "test_text_vectorized = np.array([])\n",
        "#Write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_Jxr-azM_KZ"
      },
      "source": [
        "Now that we have created our mapping, the next step is to define an embedding matrix which we will use as our input to the model. \n",
        "\n",
        "Complete the function below such that given a pre-trained word embedding and a mapping that maps each word to an integer, an embedding matrix is returned such that the word $W$ that maps to the integer $i$ in the mapping, takes the $i_{th}$ column in the matrix, with its rows equal to the corresponding values in the word embedding. \n",
        "\n",
        "Hint: You also have to take into account the Out-Of-Vocabulary words and Padding. Make sure to create your embedding matrix in a way that if a word is not in the word embedding, the embedding matrix can handle that. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBEQyJcVPkz3"
      },
      "outputs": [],
      "source": [
        "def create_emb_matrix(word_embedding, mapping, dim) : \n",
        "  embedding_matrix = np.zeros((len(mapping),dim))\n",
        "  #Write your code here \n",
        "  return embedding_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaVmoPLLQR3V"
      },
      "source": [
        "Great Job. :) \n",
        "\n",
        "Now that we have created our embedding matrix, notice that we could use the original word embedding without creating the matrix and vectorizing the sets based on the positions in the original word embedding. What do you think is the problem with this approach? Do you think there will be any performance drops if we use this approach? Explain your answer. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXweCAkQQ65Y"
      },
      "source": [
        "Type Your Answer Here: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J80Z6C9TRDNm"
      },
      "source": [
        "We have our train and test sets ready, sentences vectorized, and embedding matrix constructed. Now we can start the training process.\n",
        "\n",
        "The first step is to create a deep learning model. \n",
        "\n",
        "Complete the function below, according to what we have learned in the class, that we can use to create a model to train our data.\n",
        "\n",
        "Your code must: \n",
        "\n",
        "\n",
        "1.   Have an embedding layer which utilizes our embedding matrix and is frozen (not trainable)\n",
        "2.   Have a single binary output (our labels are binary)\n",
        "\n",
        "Note: You may use any framework that you wish. But we recommend using either Pytorch or Tensorflow/Keras so we can help if you encounter any problems. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQe0uzNKW90o"
      },
      "outputs": [],
      "source": [
        "def create_model(embedding_matrix) : \n",
        "  #Write your code here\n",
        "  return model\n",
        "model = model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F723x7xX3X3"
      },
      "source": [
        "Great. :) Now we have a model that we can use for training. \n",
        "\n",
        "In this step, we train our model on the train dataset, and use our test set to validate the model. \n",
        "\n",
        "Write a code below that uses train text and train_labels for training, and test text and test_labels for validation. Run your code for the specified number of epochs. \n",
        "\n",
        "Note: Remember that you can't use the string text for training, you have to use the vectorized versions. \n",
        "\n",
        "Note II: Utilize the provided parameters for your training. You can customize everything else. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGzbeJqmYoN6"
      },
      "outputs": [],
      "source": [
        "#@title Parameters (Don't Change)\n",
        "Epoch = 5 #@param {type:\"integer\"}\n",
        "learning_rate = 0.001 #@param {type:'number'}\n",
        "#Write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDynZAuAZRiJ"
      },
      "source": [
        "### 4.3 Utilizing Pre-Trained Word Embeddings\n",
        "\n",
        "Now that we have trained our very own NLP model and got familiar with the process. We can try at our hand in using a real, large scale pre-trained word embedding.\n",
        "\n",
        "For this task, we are going to use Glove word embeddings. Run the cell below to download it. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPqX2-SKaetC"
      },
      "outputs": [],
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-JBu_-zb9vq"
      },
      "source": [
        "Now that we have downloaded our word embeddings, we need a dictionary that maps each word to its representation using the embedding file, run the cell below to construct this mapping. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYpF6Oj1cOck",
        "outputId": "3efabe0e-1fcd-4642-d73d-4470e3ece320"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "path_to_glove_file = os.path.join(\n",
        "    os.path.expanduser(\"~\"), \"/content/glove.6B.100d.txt\"\n",
        ")\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d5yz8AGcwRi"
      },
      "source": [
        "Now that we have created our dictionary, lets look at a simple example and see how each word is mapped to its corresponding representation. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nR258ttOcmWJ",
        "outputId": "320e30a4-5ee6-49ff-aa3d-d7a9ad35f15b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.23088  ,  0.28283  ,  0.6318   , -0.59411  , -0.58599  ,\n",
              "        0.63255  ,  0.24402  , -0.14108  ,  0.060815 , -0.7898   ,\n",
              "       -0.29102  ,  0.14287  ,  0.72274  ,  0.20428  ,  0.1407   ,\n",
              "        0.98757  ,  0.52533  ,  0.097456 ,  0.8822   ,  0.51221  ,\n",
              "        0.40204  ,  0.21169  , -0.013109 , -0.71616  ,  0.55387  ,\n",
              "        1.1452   , -0.88044  , -0.50216  , -0.22814  ,  0.023885 ,\n",
              "        0.1072   ,  0.083739 ,  0.55015  ,  0.58479  ,  0.75816  ,\n",
              "        0.45706  , -0.28001  ,  0.25225  ,  0.68965  , -0.60972  ,\n",
              "        0.19578  ,  0.044209 , -0.31136  , -0.68826  , -0.22721  ,\n",
              "        0.46185  , -0.77162  ,  0.10208  ,  0.55636  ,  0.067417 ,\n",
              "       -0.57207  ,  0.23735  ,  0.4717   ,  0.82765  , -0.29263  ,\n",
              "       -1.3422   , -0.099277 ,  0.28139  ,  0.41604  ,  0.10583  ,\n",
              "        0.62203  ,  0.89496  , -0.23446  ,  0.51349  ,  0.99379  ,\n",
              "        1.1846   , -0.16364  ,  0.20653  ,  0.73854  ,  0.24059  ,\n",
              "       -0.96473  ,  0.13481  , -0.0072484,  0.33016  , -0.12365  ,\n",
              "        0.27191  , -0.40951  ,  0.021909 , -0.6069   ,  0.40755  ,\n",
              "        0.19566  , -0.41802  ,  0.18636  , -0.032652 , -0.78571  ,\n",
              "       -0.13847  ,  0.044007 , -0.084423 ,  0.04911  ,  0.24104  ,\n",
              "        0.45273  , -0.18682  ,  0.46182  ,  0.089068 , -0.18185  ,\n",
              "       -0.01523  , -0.7368   , -0.14532  ,  0.15104  , -0.71493  ],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings_index['cat']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YylyVRFchX9x"
      },
      "source": [
        "Observe that the word \"cat\" maps to a 100 dimensional space, representing the word in a vector space. \n",
        "\n",
        "Now that we have our embedding dictionary, write a code a below such that you retrrain a model on the same data, but with the help of this pre-trained embedding. Here is a breakdown of things that you must do: \n",
        "\n",
        "\n",
        "\n",
        "1.   Create a word embedding matrix from the vectorized data, such that the $i_{th}$ element of the matrix corresponds to the $i_{th}$ word in the vetorization mapping, and its columns are taken from the embedding dictionary so the pre-trained embeddings are used\n",
        "2.   Create the model with the same parameters as above\n",
        "3.   Train and validate the model under the same conditions\n",
        "\n",
        "Write your code below\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UW3UuLxjjRrh"
      },
      "outputs": [],
      "source": [
        "#@title Parameters (Don't Change)\n",
        "Epoch = 5 #@param {type:\"integer\"}\n",
        "learning_rate = 0.001 #@param {type:'number'}\n",
        "#glove_embedding_matirx = ? Define the embedding matrix here \n",
        "model = create_model(glove_embedding_matrix)\n",
        "#Train and validate your model here "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOIpXtGwju6S"
      },
      "source": [
        "### 4.4 Comparing the models\n",
        "\n",
        "Great job. So far, you have created your own word embedding, analyzed it, and trained two models using your own word embedding and a pre-trained one. In this exercise, we will discuss the differences between the model trained on our own word embedding and the model trained on a pre-trained word embedding. \n",
        "\n",
        "Answer the questions below. \n",
        "\n",
        "\n",
        "\n",
        "1.   Observe the performance difference between the two models, which model performs better under the same condition? Why do you think this is the case? Is this different from what you expected? \n",
        "2.   Propose a method by which we can increase the performance of the model that has a lower performance. Explain your answer and reasoning. \n",
        "3.   How much of a role do you think the data plays in the performance of a word embedding? What kinds of data are the best for constructing word embeddings?\n",
        "4.   Do you think that it is the case that different word embeddings might have different performances in different tasks? Explain your answer. Give examples to justify your answer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ekCFSd6lkLb"
      },
      "source": [
        "Type Your Answer Here: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGg7-09Kln15"
      },
      "source": [
        "## Exercise 5: Understanding Word2Vec\n",
        "\n",
        "Prior to Transformer models, pre-trained word embeddings were the go-to architectures to achieve state-of-the-art performance. Although their effectiveness has diminished in the recent years, it is still valuable to learn their inner workings as they cary lots of ideas that can be used even today and in your research. \n",
        "\n",
        "In this exercise, we are going to read a bit about Word2Vec, understand how it works, and hypothesize about its properties. \n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbtWT2TApC1G"
      },
      "source": [
        "###5.1 The inner workings of Word2Vec\n",
        "\n",
        "Read [this paper](https://arxiv.org/abs/1301.3781) carefully which explains how Word2Vec was developed and what its capabilities are. Then, Answer the questions below in detail. \n",
        "\n",
        "\n",
        "\n",
        "1.   Give a brief overview of the paper. What were the goals and concerns behind the project? Did the authors manage to achieve their goals? What do you think are the advantages and the shortcomings of Word2Vec? Limit your answer to 5-7 lines. \n",
        "2.   What are the tasks by which Word2Vec representations can be created? Give a brief description of each and list their advantages and disadvantages. \n",
        "3.   If you were to create your own Word2Vec embeddings using a relatively small corpus, what training task would you choose? Why? Explain your answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-ZefYTCpJ7C"
      },
      "source": [
        "Type Your Answers Here: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNx-XMpmptjI"
      },
      "source": [
        "### 5.2 Relations in Word2Vec\n",
        "\n",
        "In this question, we are going to find the relations between words in a word embedding trained using Word2Vec techniques. \n",
        "\n",
        "Run the cell below to download a Word2Vec representation trained on Google News."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3ok0CKCqZoS"
      },
      "outputs": [],
      "source": [
        "!wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n",
        "!gzip -d GoogleNews-vectors-negative300.bin.gz\n",
        "import gensim.models.keyedvectors as word2vec\n",
        "model=word2vec.KeyedVectors.load_word2vec_format(\"/content/GoogleNews-vectors-negative300.bin\",binary=True, limit = 40000)\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTSe-4gmqmhq"
      },
      "source": [
        "Now, lets use the same structure as the Bias exercise to find similarities using an analogy task. Run the code below for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sywEPSpPq-sr",
        "outputId": "c27d1e9c-7699-47b7-e2b7-d5910399220f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "France: 0.7884\n"
          ]
        }
      ],
      "source": [
        "result = model.most_similar(positive=['Germany', 'Paris'], negative=['Berlin'])\n",
        "most_similar_key, similarity = result[0]\n",
        "print(f\"{most_similar_key}: {similarity:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcQCradwrLpL"
      },
      "source": [
        "Refer to page 10 of the paper to see more examples. Using the code above, answer the questions below. \n",
        "\n",
        "\n",
        "\n",
        "1.   Can you find 10 more triplets that hold with some of the relations in page 10? Write them down. Write both the question, and the answer.\n",
        "2.   Can you find 3 triplets that you expect to hold but do not? Write them down. Write both the question, and the answer. \n",
        "3.   Why do you think that it is the case that some triplets might not hold? Can you think of a method by which we can mitigate this problem? Explain your answer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5_MVpEEsWtx"
      },
      "source": [
        "Type Your Answer Here: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qmx1FoiAyxbB"
      },
      "source": [
        "## Submission\n",
        "\n",
        "Congratulations! You finished the assignment & you're ready to submit your work. Please follow the instructions:\n",
        "\n",
        "1. Check and review your answers. Make sure all of the cell outputs are what you want. \n",
        "2. Select File > Save.\n",
        "3. **Fill your information** & run the cell bellow.\n",
        "4. Run **Make Submission** cell, It may take several minutes and it may ask you for your credential.\n",
        "5. Run **Download Submission** cell to obtain your submission as a zip file.\n",
        "6. Grab the downloaded file (`nlp_asg01__xx__xx.zip`) and hand it over in microsoft teams.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrfrCPkKzfXL"
      },
      "source": [
        "### Fill your information (Run the cell)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8pIF14Bzkod",
        "outputId": "c1637930-9d29-492d-fa36-3914ba23ce35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "your student id: \n",
            "your name: 31231\n"
          ]
        }
      ],
      "source": [
        "#@title Enter your information & \"RUN the cell!!\" { run: \"auto\" }\n",
        "student_id = \"\" #@param {type:\"string\"}\n",
        "student_name = \"\" #@param {type:\"string\"}\n",
        "\n",
        "print(\"your student id:\", student_id)\n",
        "print(\"your name:\", student_name)\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "ASSIGNMENT_PATH = Path('asg02')\n",
        "ASSIGNMENT_PATH.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roWYfsWVz0pN"
      },
      "source": [
        "### Make Submission (Run the cell)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qx19ikCy0OID"
      },
      "outputs": [],
      "source": [
        "#@title Make submission\n",
        "! pip install -U --quiet PyDrive > /dev/null\n",
        "! pip install -U --quiet jdatetime > /dev/null\n",
        "\n",
        "# ! wget -q https://github.com/github/hub/releases/download/v2.10.0/hub-linux-amd64-2.10.0.tgz \n",
        "\n",
        "\n",
        "import os\n",
        "import time\n",
        "import yaml\n",
        "import json\n",
        "import jdatetime\n",
        "\n",
        "from google.colab import files\n",
        "from IPython.display import Javascript\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "asg_name = 'NLP_Assignment_2'\n",
        "script_save = '''\n",
        "require([\"base/js/namespace\"],function(Jupyter) {\n",
        "    Jupyter.notebook.save_checkpoint();\n",
        "});\n",
        "'''\n",
        "# repo_name = 'iust-deep-learning-assignments'\n",
        "submission_file_name = 'nlp_asg02__%s__%s.zip'%(student_id, student_name.lower().replace(' ',  '_'))\n",
        "\n",
        "sub_info = {\n",
        "    'student_id': student_id,\n",
        "    'student_name': student_name, \n",
        "    'dateime': str(jdatetime.date.today()),\n",
        "    'asg_name': asg_name\n",
        "}\n",
        "json.dump(sub_info, open('info.json', 'w'))\n",
        "\n",
        "Javascript(script_save)\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "file_id = drive.ListFile({'q':\"title='%s.ipynb'\"%asg_name}).GetList()[0]['id']\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('%s.ipynb'%asg_name) \n",
        "\n",
        "! jupyter nbconvert --to script \"$asg_name\".ipynb > /dev/null\n",
        "! jupyter nbconvert --to html \"$asg_name\".ipynb > /dev/null\n",
        "! zip \"$submission_file_name\" \"$asg_name\".ipynb \"$asg_name\".html \"$asg_name\".txt info.json > /dev/null\n",
        "\n",
        "print(\"##########################################\")\n",
        "print(\"Done! Submisson created, Please download using the bellow cell!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raiAf6xv0Ahd"
      },
      "outputs": [],
      "source": [
        "drive.ListFile({'q':\"title='%s.ipynb'\"%asg_name}).GetList()[0]['id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJcHU3RC0B8c"
      },
      "outputs": [],
      "source": [
        "files.download(submission_file_name)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Vis0w0GXB0Mt",
        "uhgalvhuEUd9",
        "FUTUMjXilKli",
        "yRlG0BC1BaVi"
      ],
      "name": "NLP_Assignment_1_Word_Embeddings.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
