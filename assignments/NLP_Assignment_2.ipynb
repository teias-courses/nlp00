{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Assignment_2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "GKlAVvGvsG8i",
        "tLkASPSSL4ep",
        "0r4gKrxRFTrl",
        "z7U5s2Wgvatv",
        "E2caV8sIvfz6",
        "HUefovjcvi_N",
        "3UrkAU7zFFOl",
        "F3IVFxQyHYFU",
        "oJ6vrUU9GNYM",
        "0cvazKqVCDx2",
        "CoBIAGlLJVlt",
        "Iv9C-VHoyMIF",
        "XliTnkI8gvLR"
      ],
      "authorship_tag": "ABX9TyNd5orxbX1GArk+TOyeq9iZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/teias-courses/nlp99/blob/gh-pages/assignments/NLP_Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKlAVvGvsG8i"
      },
      "source": [
        "# NLP Assignment #02 - NLP with tight hands!\n",
        "Deep Learning / Spring 1400, Khatam University\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-_PRgRX1NDO"
      },
      "source": [
        "**Please pay attention to these notes:**\n",
        "<br><br>\n",
        "\n",
        "\n",
        "- **Assignment Due:** <b><font color='red'>1400.01.18</font></b> 23:59:00\n",
        "- If you need any additional information, please review the assignment page on the course website.\n",
        "- The items you need to answer are highlighted in <font color=\"SeaGreen\">**bold SeaGreen**</font> and the coding parts you need to implement are denoted by:\n",
        "```\n",
        "# ------------------\n",
        "# Put your implementation here     \n",
        "# ------------------\n",
        "```\n",
        "- We always recommend co-operation and discussion in groups for assignments. However, **each student has to finish all the questions by him/herself**. If our matching system identifies any sort of copying, you'll be responsible for consequences.\n",
        "- Students who audit this course should submit their assignments like other students to be qualified for attending the rest of the sessions.\n",
        "- If you have any questions about this assignment, feel free to drop us a line. You may also post your questions on the course Microsoft Teams channel.\n",
        "- You must run this notebook on Google Colab platform, it depends on Google Colab VM for some of the depencecies.\n",
        "- You can double click on collapsed code cells to expand them.\n",
        "- <b><font color='red'>When you are ready to submit, please follow the instructions at the end of this notebook.</font></b>\n",
        "\n",
        "\n",
        "<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLkASPSSL4ep"
      },
      "source": [
        "# Introduction\n",
        "In this assignment, we are going to get a taste of what NLP was before introduction of RNNs! The rules are simple: no **RNN** or **Transformer** architectures are allowed! But you are allowed to use everything else!\n",
        "\n",
        "We will go through all different kinds of standard NLP tasks one by one. For each task we chose a well known relevant dataset. We also provide a very basic baseline for each task, so you can compare the performance of your model.\n",
        "\n",
        "Two of these tasks will be evaluated right here in this notebook, but for the other three, you have to submit your results to a Kaggle competition. Are you able to secure the first place in the leaderboard? Let's see :) \n",
        "\n",
        "<b><font color='red'>There are no questions for you in this notebook, you also have freedome in your implementations, but note that you will have to defend your proposed method and ideas in a video call with one of the TAs.</font></b>\n",
        "\n",
        "Let's begin! Run the following cell:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "layMpCLp1wfe",
        "cellView": "form"
      },
      "source": [
        "# @title Install, Load libs\n",
        "\n",
        "!pip install --upgrade scikit-learn\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch, torchtext\n",
        "import spacy\n",
        "from sklearn.metrics import top_k_accuracy_score, f1_score, accuracy_score\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "import pickle\n",
        "import re, os, string, typing, gc, json, random\n",
        "from collections import Counter\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "clear_output()\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0r4gKrxRFTrl"
      },
      "source": [
        "# Yelp (Text Classification - Sentiment Analysis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8y7BjALuSMV"
      },
      "source": [
        "**Sentiment Analysis** is the process of detecting positive or negative sentiment in text. Sentiment analysis models focus on polarity (positive, negative, neutral) but also on feelings and emotions (angry, happy, sad, etc), urgency (urgent, not urgent) and even intentions (interested v. not interested). If polarity precision is important to you, you might consider expanding your polarity categories to include:\n",
        "\n",
        "*   Very positive\n",
        "*   Positive\n",
        "*   Neutral\n",
        "*   Negative\n",
        "*   Very negative\n",
        "\n",
        "In this assignment we just focus on a bi-polar sentiment analysis, therefore each sample is either a positive sample or negative sample. Here we use **Yelp**, which is one of the most well-known datasets for sentiment analysis.Note that the dataset is available in `torchtext` module, so we don't need to download it explicitly.\n",
        "\n",
        "## Technical Notes:\n",
        "\n",
        "* You can use any data for model training, except Yelp test set which is used for final evaluation.\n",
        "\n",
        "* Your model should be compatible with our `predict_dataset` function which returns predicted sentiment for all dataset examples. Or you can implement your own version of `predict_dataset` which returns same output without shuffling data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7U5s2Wgvatv"
      },
      "source": [
        "## Our Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdLxdycPIOmJ",
        "cellView": "form"
      },
      "source": [
        "#@title Load GloVe embeddings\n",
        "\n",
        "EMBEDDING_DIM = 100 #@param {type:\"integer\"}\n",
        "glove = torchtext.vocab.GloVe(name='6B', dim=EMBEDDING_DIM)\n",
        "\n",
        "word2id = glove.stoi\n",
        "PAD_TOKEN_ID = len(word2id)\n",
        "word2id['<unk>'] = len(word2id)\n",
        "UNK_TOKEN_ID = len(word2id)\n",
        "word2id['<pad>'] = len(word2id)\n",
        "\n",
        "def convert_to_ids(tokens, pad=True, truncate=True, maxlen=32):\n",
        "  ids = [word2id[token] if token in word2id else UNK_TOKEN_ID for token in tokens]\n",
        "  if pad:\n",
        "   ids = ids + [PAD_TOKEN_ID] * (maxlen-len(ids))\n",
        "  if truncate:\n",
        "   ids = ids[:maxlen]\n",
        "  return ids\n",
        "\n",
        "clear_output()\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRScfcQWJPFU",
        "cellView": "form"
      },
      "source": [
        "#@title Load dataset\n",
        "\n",
        "BATCH_SIZE = 128 #@param {type:\"integer\"}\n",
        "MAXLEN = 64 #@param {type:\"integer\"}\n",
        "\n",
        "class SentimentDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, split_name='train', maxlen=160, label_map=None, num_examples=None):\n",
        "    super().__init__()\n",
        "\n",
        "    raw_dataset = torchtext.datasets.YelpReviewPolarity(split=split_name)\n",
        "    tokenizer = spacy.load('en')\n",
        "\n",
        "    # 'train', 'valid', 'test'\n",
        "    if not num_examples:\n",
        "      num_examples = len(raw_dataset)\n",
        "\n",
        "    self.examples = []\n",
        "    raw_data_iter = iter(raw_dataset)\n",
        "    for i in range(num_examples):\n",
        "      l, s = next(raw_data_iter)\n",
        "      tokens = [t.text for t in tokenizer(s.lower(), disable=['parser','tagger','ner'])]\n",
        "      self.examples.append((l, tokens))\n",
        "    \n",
        "    self.maxlen = maxlen\n",
        "    self.label_map = label_map\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.examples)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    label, tokens = self.examples[index]\n",
        "    token_ids = convert_to_ids(tokens, maxlen=self.maxlen)\n",
        "    \n",
        "    label_id = self.label_map[label]\n",
        "    return (torch.tensor(token_ids),\n",
        "            torch.tensor(label_id))\n",
        "\n",
        "label_map = {1:0, 2:1}\n",
        "\n",
        "yelp_train = SentimentDataset(split_name='train', \n",
        "                              maxlen=MAXLEN, \n",
        "                              label_map=label_map,\n",
        "                              num_examples=55_000)\n",
        "\n",
        "yelp_train, yelp_dev = torch.utils.data.random_split(yelp_train, [50_000, 5000])\n",
        "\n",
        "yelp_test = SentimentDataset(split_name='test', \n",
        "                             maxlen=MAXLEN, \n",
        "                             label_map=label_map)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(yelp_train,\n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           shuffle=True)\n",
        "\n",
        "clear_output()\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwYc6edsHDT2",
        "cellView": "form"
      },
      "source": [
        "#@title Define baseline model\n",
        "\n",
        "class SentimentBaseline(torch.nn.Module):\n",
        "  def __init__(self, word_embeddings, num_classes):\n",
        "    super().__init__()\n",
        "    \n",
        "    embedding_dim = word_embeddings.dim\n",
        "\n",
        "    self.embedding = torch.nn.Embedding(len(word2id), embedding_dim, padding_idx=PAD_TOKEN_ID)\n",
        "    self.embedding.weight.data.copy_(torch.cat([\n",
        "        word_embeddings.vectors,\n",
        "        torch.rand_like(word_embeddings.vectors[:1]),  # unk\n",
        "        torch.zeros_like(word_embeddings.vectors[:1])  # pad\n",
        "      ], dim=0))\n",
        "\n",
        "    self.classifier = torch.nn.Linear(embedding_dim, num_classes, bias=False)\n",
        "\n",
        "  def forward(self, sent_toks):\n",
        "    sent_emb = self.embedding(sent_toks)\n",
        "    sent_mean = (sent_emb).mean(dim=1)\n",
        "    logits = self.classifier(sent_mean)\n",
        "    return logits\n",
        "\n",
        "model = SentimentBaseline(word_embeddings=glove, num_classes=2).cuda()\n",
        "\n",
        "for p in model.embedding.parameters():\n",
        "  p.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow31ghrW3p6o",
        "cellView": "form"
      },
      "source": [
        "# @title Get predictions on dataset\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_dataset(model, dataset):\n",
        "  data_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "  all_labels, all_preds = [], []\n",
        "\n",
        "  for sentence, labels in data_loader:\n",
        "    logits = model(sentence.cuda())\n",
        "    preds = torch.argmax(logits, dim=1)\n",
        "    all_preds.append(preds)\n",
        "    all_labels.append(labels)\n",
        "\n",
        "  return (torch.cat(all_labels, dim=0).cpu().numpy(),\n",
        "          torch.cat(all_preds, dim=0).cpu().numpy())\n",
        "\n",
        "# test_labels, test_preds = predict_dataset(model, yelp_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPm7K1zuHDT3",
        "cellView": "form"
      },
      "source": [
        "#@title Training loop\n",
        "\n",
        "EPOCHS = 5   #@param {type: \"integer\"}\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "criterion = torch.nn.CrossEntropyLoss() \n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  train_losses, train_corrects, train_total = [], 0, 0\n",
        "  progress = tqdm(train_loader,  desc=f'EPOCH {epoch+1}', mininterval=0.5)\n",
        "\n",
        "  for i, (sentences, labels) in enumerate(progress):  # loop over the dataset multiple times\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    logits = model(sentences.cuda())\n",
        "    loss = criterion(logits, labels.cuda())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    preds = logits.argmax(dim=-1)\n",
        "    train_corrects += (preds == labels.cuda()).sum().item()\n",
        "    train_total += len(sentences)\n",
        "\n",
        "    progress.set_postfix(loss=loss.item())\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "  dev_labels, dev_preds = predict_dataset(model, yelp_dev)\n",
        "  progress.set_postfix(train_loss=sum(train_losses)/len(train_losses),\n",
        "                       train_acc=train_corrects/train_total,\n",
        "                       dev_acc=accuracy_score(dev_labels, dev_preds))\n",
        "  progress.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2caV8sIvfz6"
      },
      "source": [
        "## Your Model(s)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCp2ak0F0mAJ"
      },
      "source": [
        "# ------------------\n",
        "# Put your implementation here (Multi Cell)    \n",
        "# ------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUefovjcvi_N"
      },
      "source": [
        "## Submit/Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxeaOur58xyv"
      },
      "source": [
        "test_labels, test_preds = predict_dataset(model, yelp_test)\n",
        "accuracy = accuracy_score(test_labels, test_preds)\n",
        "print(f'Accuracy on test set: {accuracy*100:.1f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UrkAU7zFFOl"
      },
      "source": [
        "#STS (Text Regression - Semantic Textual Similarity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrJlX2mCwpXg"
      },
      "source": [
        "**Semantic Textual Similarity (STS)** measures the meaning similarity of sentences. STS deals with determining how similar two pieces of texts are. This can take the form of assigning a score from 1 to 5.\n",
        "\n",
        "For this task, we use STS dataset available at Glue benchmark. You can take a look [here](http://ixa2.si.ehu.eus/stswiki/index.php/STSbenchmark) to find more relevant information, including a table with different baselines for comparison.\n",
        "\n",
        "## Technical Notes:\n",
        "\n",
        "* You can use any data for model training, except STS test set which is used for final evaluation.\n",
        "\n",
        "* Your model should be compatible with our `predict_dataset` function which returns predicted score for all dataset examples. Or you can implement your own version of `predict_dataset` which returns same output without shuffling data.\n",
        "\n",
        "* <b><font color='red'>After local evaluation, submit (upload) your results to [this competition](https://www.kaggle.com/t/40245eaca8ab4b19befe06f18af12b2f) and compete with your classmates.</font></b> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP25liD5d9nJ",
        "cellView": "form"
      },
      "source": [
        "# @title Download dataset\n",
        "!wget https://dl.fbaipublicfiles.com/glue/data/STS-B.zip\n",
        "!unzip /content/STS-B.zip\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3IVFxQyHYFU"
      },
      "source": [
        "## Our Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiZ7tbJRd9nK",
        "cellView": "form"
      },
      "source": [
        "#@title Load GloVe embeddings\n",
        "\n",
        "EMBEDDING_DIM = 100 #@param {type:\"integer\"}\n",
        "glove = torchtext.vocab.GloVe(name='6B', dim=EMBEDDING_DIM)\n",
        "\n",
        "word2id = glove.stoi\n",
        "PAD_TOKEN_ID = len(word2id)\n",
        "word2id['<unk>'] = len(word2id)\n",
        "UNK_TOKEN_ID = len(word2id)\n",
        "word2id['<pad>'] = len(word2id)\n",
        "\n",
        "def convert_to_ids(tokens, pad=True, truncate=True, maxlen=32):\n",
        "  ids = [word2id[token] if token in word2id else UNK_TOKEN_ID for token in tokens]\n",
        "  if pad:\n",
        "   ids = ids + [PAD_TOKEN_ID] * (maxlen-len(ids))\n",
        "  if truncate:\n",
        "   ids = ids[:maxlen]\n",
        "  return ids\n",
        "\n",
        "clear_output()\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbYWP5PNd9nL",
        "cellView": "form"
      },
      "source": [
        "#@title Load dataset\n",
        "\n",
        "BATCH_SIZE = 128 #@param {type:\"integer\"}\n",
        "MAXLEN = 64 #@param {type:\"integer\"}\n",
        "\n",
        "class STSDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, split_path=None, maxlen=160, num_examples=None):\n",
        "    super().__init__()\n",
        "\n",
        "    df = pd.read_csv(split_path, error_bad_lines=False, sep='\\t').dropna()\n",
        "    num_examples = num_examples or len(df)\n",
        "    df = df.iloc[:num_examples]\n",
        "    \n",
        "    tokenizer = spacy.load('en')\n",
        "\n",
        "    self.examples = []\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "      score = row['score']\n",
        "      s1, s2 = row['sentence1'], row['sentence2']\n",
        "      tokens1 = [t.text for t in tokenizer(s1.lower(), disable=['parser','tagger','ner'])]\n",
        "      tokens2 = [t.text for t in tokenizer(s2.lower(), disable=['parser','tagger','ner'])]\n",
        "      \n",
        "      self.examples.append((score, tokens1, tokens2))\n",
        "    \n",
        "    self.maxlen = maxlen\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.examples)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    score, tokens1, tokens2 = self.examples[index]\n",
        "    token_ids1 = convert_to_ids(tokens1, maxlen=self.maxlen)\n",
        "    token_ids2 = convert_to_ids(tokens2, maxlen=self.maxlen)\n",
        "    \n",
        "    return (torch.tensor(token_ids1),\n",
        "            torch.tensor(token_ids2),\n",
        "            torch.tensor(score))\n",
        "\n",
        "\n",
        "sts_train = STSDataset(split_path='/content/STS-B/train.tsv', \n",
        "                       maxlen=MAXLEN)\n",
        "\n",
        "sts_test = STSDataset(split_path='/content/STS-B/dev.tsv',\n",
        "                      maxlen=MAXLEN)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(sts_train,\n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(sts_test,\n",
        "                                          batch_size=BATCH_SIZE,\n",
        "                                          shuffle=True)\n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxHFNSDFCj78",
        "cellView": "form"
      },
      "source": [
        "#@title Define baseline model\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class STSBaseline(torch.nn.Module):\n",
        "  def __init__(self, word_embeddings):\n",
        "    super().__init__()\n",
        "\n",
        "    embedding_dim = word_embeddings.dim\n",
        "\n",
        "    self.embedding = torch.nn.Embedding(len(word2id), embedding_dim, padding_idx=PAD_TOKEN_ID)\n",
        "    self.embedding.weight.data.copy_(torch.cat([\n",
        "      word_embeddings.vectors,\n",
        "      torch.rand_like(word_embeddings.vectors[:1]),\n",
        "      torch.zeros_like(word_embeddings.vectors[:1])], dim=0))\n",
        "    \n",
        "    self.cosine = torch.nn.CosineSimilarity(dim=-1)\n",
        "\n",
        "  def forward(self, sent1_toks, sent2_toks):\n",
        "    sent1_emb = self.embedding(sent1_toks)\n",
        "    sent2_emb = self.embedding(sent2_toks)\n",
        "\n",
        "    sent1_mean = (sent1_emb).mean(dim=1)\n",
        "    sent2_mean = (sent2_emb).mean(dim=1)\n",
        "\n",
        "    score = 2.5 * (self.cosine(sent1_mean, sent2_mean) + 1)\n",
        "    \n",
        "    return score\n",
        "\n",
        "model = STSBaseline(glove).cuda()\n",
        "\n",
        "for p in model.embedding.parameters():\n",
        "  p.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7Xh_wN8E9lo",
        "cellView": "form"
      },
      "source": [
        "# @title Get predictions on dataset\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_dataset(model, dataset):\n",
        "  data_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "  all_scores, all_preds = [], []\n",
        "\n",
        "  for s1, s2, scores in data_loader:\n",
        "    preds = model(s1.cuda(), s2.cuda())\n",
        "    all_preds.append(preds)\n",
        "    all_scores.append(scores)\n",
        "\n",
        "  return (torch.cat(all_scores, dim=0).cpu().numpy(),\n",
        "          torch.cat(all_preds, dim=0).cpu().numpy())\n",
        "\n",
        "# test_scores, test_preds = predict_dataset(model, sts_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJ6vrUU9GNYM"
      },
      "source": [
        "## Your Model(s)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYNjsyZmGNYO"
      },
      "source": [
        "# ------------------\n",
        "# Put your implementation here (Multi Cell)    \n",
        "# ------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zoKazhuGNYP"
      },
      "source": [
        "## Submit/Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9W7uZM-3nog",
        "cellView": "form"
      },
      "source": [
        "#@title Pearson correlation\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "test_scores, test_preds = predict_dataset(model, sts_test)\n",
        "pearon_coef = pearsonr(test_scores, test_preds)[0]\n",
        "print(f'Pearson correlation coefficient: {pearon_coef:.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "JOnnVKN78oGi"
      },
      "source": [
        "#@title Spearman correlation\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "test_scores, test_preds = predict_dataset(model, sts_test)\n",
        "spearman_coef = spearmanr(test_scores, test_preds)[0]\n",
        "print(f'Pearson correlation coefficient: {spearman_coef:.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVT7v3fbGitX",
        "cellView": "form"
      },
      "source": [
        "# @title Scatter plot (real, predicted scores)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(test_scores, test_preds, '.')\n",
        "plt.xlabel('Real similarity scores')\n",
        "plt.ylabel('Predicted scores')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmLHCy7-C863",
        "cellView": "form"
      },
      "source": [
        "# @title Make kaggle submission file\n",
        "from google.colab import files\n",
        "\n",
        "with open('sts_submission.csv', 'w') as f:\n",
        "  S = 'id,score\\n'\n",
        "  for i, score in enumerate(test_preds):\n",
        "    S += f'{i},{score}\\n'\n",
        "  f.write(S[:-1])\n",
        "\n",
        "files.download('sts_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cvazKqVCDx2"
      },
      "source": [
        "# SNLI (Text Classification - Natural Language Inference)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voLONqCJ0S9w"
      },
      "source": [
        "**Natural language inference (NLI)** is a fundamental NLP task, investigating the entailment relationship between two texts.\n",
        "\n",
        "The **SNLI corpus** is a collection of 570k human-written English sentence pairs manually labeled for balanced classification with the labels entailment, contradiction, and neutral, supporting the task of natural language inference (NLI). Take a look at [here](https://nlp.stanford.edu/projects/snli/) to find more relevant information.\n",
        "\n",
        "## Technical Notes:\n",
        "\n",
        "* You can use any data for model training, except SNLI test set which is used for final evaluation.\n",
        "\n",
        "* Your model should be compatible with our `predict_dataset` function which returns predicted class for all dataset examples (`numpy array with shape: (NUM_EXAMPLES,)`). Or you can implement your own version of `predict_dataset` which returns same output without shuffling data.\n",
        "\n",
        "* <b><font color='red'>After local evaluation, submit (upload) your results to [this competition](https://www.kaggle.com/t/f394320514e24db3b668982d44164510) and compete with your classmates.</font></b> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqefYZaDCDx7",
        "cellView": "form"
      },
      "source": [
        "#@title Download dataset\n",
        "!wget https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
        "!unzip snli_1.0.zip\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZYzk1xbHeUp"
      },
      "source": [
        "## Our Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akFJQdJTWAuv",
        "cellView": "form"
      },
      "source": [
        "#@title Load GloVe embeddings\n",
        "\n",
        "EMBEDDING_DIM = 100 #@param {type:\"integer\"}\n",
        "glove = torchtext.vocab.GloVe(name='6B', dim=EMBEDDING_DIM)\n",
        "\n",
        "word2id = glove.stoi\n",
        "PAD_TOKEN_ID = len(word2id)\n",
        "word2id['<unk>'] = len(word2id)\n",
        "UNK_TOKEN_ID = len(word2id)\n",
        "word2id['<pad>'] = len(word2id)\n",
        "\n",
        "def convert_to_ids(tokens, pad=True, truncate=True, maxlen=32):\n",
        "  ids = [word2id[token] if token in word2id else UNK_TOKEN_ID for token in tokens]\n",
        "  if pad:\n",
        "   ids = ids + [PAD_TOKEN_ID] * (maxlen-len(ids))\n",
        "  if truncate:\n",
        "   ids = ids[:maxlen]\n",
        "  return ids\n",
        "\n",
        "clear_output()\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvqAim8PWAu1",
        "cellView": "form"
      },
      "source": [
        "#@title Load dataset\n",
        "\n",
        "BATCH_SIZE = 128 #@param {type:\"integer\"}\n",
        "MAXLEN = 64 #@param {type:\"integer\"}\n",
        "\n",
        "class SNLIDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, split_path=None, maxlen=160, label_map=None, num_examples=None):\n",
        "    super().__init__()\n",
        "    \n",
        "    df = pd.read_csv(split_path, sep=\"\\t\").dropna(subset=[\"gold_label\", \"sentence1\", \"sentence2\"])\n",
        "    df = df[(df['gold_label'] == 'contradiction')|(df['gold_label'] == 'neutral')|(df['gold_label'] == 'entailment')]\n",
        "    num_examples = num_examples or len(df)\n",
        "    df = df.iloc[:num_examples]\n",
        "    \n",
        "    tokenizer = spacy.load('en')\n",
        "\n",
        "    self.examples = []\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "      label = row['gold_label']\n",
        "      s1, s2 = row['sentence1'], row['sentence2']\n",
        "      tokens1 = [t.text for t in tokenizer(s1.lower(), disable=['parser','tagger','ner'])]\n",
        "      tokens2 = [t.text for t in tokenizer(s2.lower(), disable=['parser','tagger','ner'])]\n",
        "      \n",
        "      self.examples.append((label, tokens1, tokens2))\n",
        "    \n",
        "    self.maxlen = maxlen\n",
        "    self.label_map = label_map\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.examples)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    label, tokens1, tokens2 = self.examples[index]\n",
        "    token_ids1 = convert_to_ids(tokens1, maxlen=self.maxlen)\n",
        "    token_ids2 = convert_to_ids(tokens2, maxlen=self.maxlen)\n",
        "    \n",
        "    label_id = self.label_map[label]\n",
        "    return (torch.tensor(token_ids1),\n",
        "            torch.tensor(token_ids2),\n",
        "            torch.tensor(label_id))\n",
        "\n",
        "\n",
        "label_map = {'contradiction':0,\n",
        "             'neutral':1,\n",
        "             'entailment':2}\n",
        "\n",
        "snli_train = SNLIDataset(split_path='/content/snli_1.0/snli_1.0_train.txt', \n",
        "                        maxlen=MAXLEN, \n",
        "                        label_map=label_map,\n",
        "                        num_examples=50000)\n",
        "\n",
        "snli_dev = SNLIDataset(split_path='/content/snli_1.0/snli_1.0_dev.txt', \n",
        "                        maxlen=MAXLEN, \n",
        "                        label_map=label_map,\n",
        "                        num_examples=5000)\n",
        "\n",
        "snli_test = SNLIDataset(split_path='/content/snli_1.0/snli_1.0_test.txt', \n",
        "                        maxlen=MAXLEN, \n",
        "                        label_map=label_map)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(snli_train,\n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           shuffle=True)\n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiSkfDAgCDyE",
        "cellView": "form"
      },
      "source": [
        "#@title Define baseline model\n",
        "\n",
        "class NLIBaseline(torch.nn.Module):\n",
        "  def __init__(self, word_embeddings, num_classes=3):\n",
        "    super().__init__()\n",
        "\n",
        "    embedding_dim = word_embeddings.dim\n",
        "\n",
        "    self.embedding = torch.nn.Embedding(len(word2id), embedding_dim, padding_idx=PAD_TOKEN_ID)\n",
        "    self.embedding.weight.data.copy_(torch.cat([\n",
        "      word_embeddings.vectors,\n",
        "      torch.rand_like(word_embeddings.vectors[:1]),\n",
        "      torch.zeros_like(word_embeddings.vectors[:1])], dim=0))\n",
        "\n",
        "    self.predictor = torch.nn.Linear(embedding_dim*2, num_classes, bias=False)\n",
        "\n",
        "  def forward(self, sent1_toks, sent2_toks):\n",
        "    sent1_emb = self.embedding(sent1_toks)\n",
        "    sent2_emb = self.embedding(sent2_toks)\n",
        "    \n",
        "    sent1_mean = (sent1_emb).mean(dim=1)\n",
        "    sent2_mean = (sent2_emb).mean(dim=1)\n",
        "    \n",
        "    conc = torch.cat([sent1_mean, sent2_mean], dim=-1)\n",
        "    logits = self.predictor(conc)\n",
        "    return logits\n",
        "\n",
        "\n",
        "model = NLIBaseline(glove, num_classes=3).cuda()\n",
        "\n",
        "for p in model.embedding.parameters():\n",
        "  p.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7WBZyiPemT6",
        "cellView": "form"
      },
      "source": [
        "# @title Get predictions on dataset\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_dataset(model, dataset):\n",
        "  data_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "  all_labels, all_preds = [], []\n",
        "\n",
        "  for sent1, sent2, label in data_loader:\n",
        "    logits = model(sent1.cuda(), sent2.cuda())\n",
        "    preds = torch.argmax(logits, dim=1)\n",
        "    all_preds.append(preds)\n",
        "    all_labels.append(label)\n",
        "\n",
        "  return (torch.cat(all_labels, dim=0).cpu().numpy(),\n",
        "          torch.cat(all_preds, dim=0).cpu().numpy())\n",
        "\n",
        "# test_labels, test_preds = predict_dataset(model, snli_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "AwfXDv-Tdpoh"
      },
      "source": [
        "#@title Training loop\n",
        "\n",
        "LR = 0.01 #@param {type: \"number\"}\n",
        "EPOCHS = 10   #@param {type: \"integer\"}\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR) \n",
        "criterion = torch.nn.CrossEntropyLoss() \n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  train_losses, train_corrects, train_total = [], 0, 0\n",
        "  progress = tqdm(train_loader,  desc=f'EPOCH {epoch+1}', mininterval=0.5)\n",
        "\n",
        "  for i, (sent1, sent2, label) in enumerate(progress):  # loop over the dataset multiple times\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    logits = model(sent1.cuda(), sent2.cuda())\n",
        "    loss = criterion(logits, label.cuda())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    preds = logits.argmax(dim=-1)\n",
        "    train_corrects += (preds == label.cuda()).sum().item()\n",
        "    train_total += len(sent1)\n",
        "\n",
        "    progress.set_postfix(loss=loss.item())\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "  dev_labels, dev_preds = predict_dataset(model, snli_dev)\n",
        "  progress.set_postfix(train_loss=sum(train_losses)/len(train_losses),\n",
        "                       train_acc=train_corrects/train_total,\n",
        "                       dev_acc=accuracy_score(dev_labels, dev_preds))\n",
        "  progress.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoBIAGlLJVlt"
      },
      "source": [
        "## Your Model(s)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzZd_eqhJVlu"
      },
      "source": [
        "# ------------------\n",
        "# Put your implementation here (Multi Cell)    \n",
        "# ------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "167bW0S2JVlv"
      },
      "source": [
        "## Submit/Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVh2mLT6JVlv"
      },
      "source": [
        "test_labels, test_preds = predict_dataset(model, snli_test)\n",
        "accuracy = accuracy_score(test_labels, test_preds)\n",
        "print(f'Accuracy on test set: {accuracy*100:.1f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUd6YTqxDJ0b"
      },
      "source": [
        "# @title Make kaggle submission file\n",
        "from google.colab import files\n",
        "\n",
        "with open('snli_submission.csv', 'w') as f:\n",
        "  S = 'id,label\\n'\n",
        "  for i, label in enumerate(test_preds):\n",
        "    S += f'{i},{label}\\n'\n",
        "  f.write(S[:-1])\n",
        "\n",
        "files.download('snli_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv9C-VHoyMIF"
      },
      "source": [
        "# UDPoS (Sequence Labeling - Part of Speech Tagging)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwioaheQa4V_"
      },
      "source": [
        "**Part of Speech tagging (PoS tagging)** is the task of tagging a word in a text with its part of speech. A part of speech is a category of words with similar grammatical properties. Common English parts of speech are noun, verb, adjective, adverb, pronoun, preposition, conjunction, etc.\n",
        "\n",
        "**Universal Dependencies (UD)** is a framework for cross-linguistic grammatical annotation, which contains more than 100 treebanks in over 60 languages. In this assignment we are targeting the English dataset (which is also available in `torchtext`). Look at [here](https://universaldependencies.org/u/pos/index.html) for more information.\n",
        "\n",
        "## Technical Notes:\n",
        "\n",
        "* You can use any data for model training, except English UDPoS test set which is used for final evaluation.\n",
        "\n",
        "* Your model should be compatible with our `predict_dataset` function which returns predicted PoS for all dataset examples. Or you can implement your own version of `predict_dataset` which returns same output without shuffling data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XliTnkI8gvLR"
      },
      "source": [
        "## Our Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "L-MBaM_NgvLY"
      },
      "source": [
        "#@title Load GloVe embeddings\n",
        "\n",
        "EMBEDDING_DIM = 100 #@param {type:\"integer\"}\n",
        "glove = torchtext.vocab.GloVe(name='6B', dim=EMBEDDING_DIM)\n",
        "\n",
        "word2id = glove.stoi\n",
        "PAD_TOKEN_ID = len(word2id)\n",
        "word2id['<unk>'] = len(word2id)\n",
        "UNK_TOKEN_ID = len(word2id)\n",
        "word2id['<pad>'] = len(word2id)\n",
        "\n",
        "def convert_to_ids(tokens, pad=True, truncate=True, maxlen=32):\n",
        "  ids = [word2id[token] if token in word2id else UNK_TOKEN_ID for token in tokens]\n",
        "  if pad:\n",
        "   ids = ids + [PAD_TOKEN_ID] * (maxlen-len(ids))\n",
        "  if truncate:\n",
        "   ids = ids[:maxlen]\n",
        "  return ids\n",
        "\n",
        "clear_output()\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIMLYnPDVtTr",
        "cellView": "form"
      },
      "source": [
        "#@title Load dataset\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "BATCH_SIZE = 128 #@param {type:\"integer\"}\n",
        "MAXLEN = 64 #@param {type:\"integer\"}\n",
        "PAD_TARGET_LABEL = -1\n",
        "\n",
        "\n",
        "class PosDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, split_name='train', maxlen=160, label_map=None):\n",
        "    super().__init__()\n",
        "    self.label_map = label_map\n",
        "\n",
        "    raw_dataset = torchtext.datasets.UDPOS(split=split_name)\n",
        "\n",
        "    self.examples = list(raw_dataset)\n",
        "    self.maxlen = maxlen\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.examples)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    tokens, udpos, _ = self.examples[index]\n",
        "    token_ids = convert_to_ids(tokens, maxlen=self.maxlen)\n",
        "    label_ids = [self.label_map[label] for label in udpos][:self.maxlen]\n",
        "    label_ids = label_ids + [PAD_TARGET_LABEL] * (self.maxlen - len(label_ids))\n",
        "    return (torch.tensor(token_ids),\n",
        "            torch.tensor(label_ids))\n",
        "    \n",
        "def get_label_map(dataset):\n",
        "  vocab = {}\n",
        "  maxlen = 0\n",
        "  counter, label2id = Counter(), {}\n",
        "  for tokens, udpos1, udpos2 in dataset:\n",
        "    counter.update(udpos1)\n",
        "    maxlen = max(maxlen, len(tokens))\n",
        "  print(maxlen)\n",
        "  for label, _ in counter.most_common():\n",
        "    label2id[label] = label2id.get(label) or len(label2id)\n",
        "  return label2id\n",
        "\n",
        "pos_train = torchtext.datasets.UDPOS(split='train')\n",
        "label_map = get_label_map(pos_train)\n",
        "\n",
        "pos_train = PosDataset('train', maxlen=MAXLEN, label_map=label_map)\n",
        "pos_dev = PosDataset('valid', maxlen=MAXLEN, label_map=label_map)\n",
        "pos_test = PosDataset('test', maxlen=MAXLEN, label_map=label_map)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(pos_train,\n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           shuffle=True)\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzMPQUH1O00J",
        "cellView": "form"
      },
      "source": [
        "# @title Define baseline model\n",
        "\n",
        "class PosBaseline(torch.nn.Module):\n",
        "  def __init__(self, word_embeddings, num_classes):\n",
        "    super().__init__()\n",
        "\n",
        "    embedding_dim = word_embeddings.dim\n",
        "\n",
        "    self.embedding = torch.nn.Embedding(len(word2id), embedding_dim, padding_idx=PAD_TOKEN_ID)\n",
        "    self.embedding.weight.data.copy_(torch.cat([\n",
        "      word_embeddings.vectors,\n",
        "      torch.rand_like(word_embeddings.vectors[:1]),\n",
        "      torch.zeros_like(word_embeddings.vectors[:1])], dim=0))\n",
        "    \n",
        "    self.classifier = torch.nn.Linear(embedding_dim, num_classes)\n",
        "\n",
        "  def forward(self, token_ids):\n",
        "    token_embs = self.embedding(token_ids)\n",
        "    logits = self.classifier(token_embs)\n",
        "    return logits\n",
        "\n",
        "NUM_CLASSES = len(label_map)\n",
        "model = PosBaseline(glove, num_classes=NUM_CLASSES).cuda()\n",
        "\n",
        "for p in model.embedding.parameters():\n",
        "  p.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d-heNp1cVDi",
        "cellView": "form"
      },
      "source": [
        "# @title Get predictions on dataset\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_dataset(model, dataset):\n",
        "\n",
        "  all_preds, all_labels = [], []\n",
        "  test_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "  \n",
        "  for ids, labels in test_loader:\n",
        "    logits = model(ids.cuda())\n",
        "    preds = logits.argmax(dim=-1)\n",
        "    all_preds.append(preds[labels != PAD_TARGET_LABEL])\n",
        "    all_labels.append(labels[labels != PAD_TARGET_LABEL])\n",
        "\n",
        "  return (torch.cat(all_labels, dim=0).cpu().numpy(),\n",
        "          torch.cat(all_preds, dim=0).cpu().numpy())\n",
        "\n",
        "all_labels, all_preds = predict_dataset(model, pos_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHJ90N2KOpx5",
        "cellView": "form"
      },
      "source": [
        "#@title Training loop\n",
        "\n",
        "EPOCHS = 10   #@param {type: \"integer\"}\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=PAD_TARGET_LABEL)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  progress = tqdm(train_loader, desc=f'EPOCH {epoch+1}')\n",
        "  \n",
        "  train_losses, train_corrects, train_total = [], 0, 0\n",
        "  for token_ids, labels in progress:\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    labels = labels.cuda().flatten()\n",
        "    logits = model(token_ids.cuda())\n",
        "    logits = logits.view(-1, logits.shape[-1])\n",
        "    loss = criterion(logits, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    preds = logits.argmax(dim=-1)\n",
        "    train_corrects += (preds[labels != PAD_TARGET_LABEL] == labels[labels != PAD_TARGET_LABEL]).sum().item()\n",
        "    train_total += len(labels[labels != PAD_TARGET_LABEL])\n",
        "\n",
        "    progress.set_postfix(loss=loss.item())\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "  dev_labels, dev_preds = predict_dataset(model, pos_dev)\n",
        "\n",
        "  progress.set_postfix(train_loss=sum(train_losses)/len(train_losses),\n",
        "                       train_acc=train_corrects/train_total,\n",
        "                       dev_acc=accuracy_score(dev_labels, dev_preds),\n",
        "                       dev_macro_f1=f1_score(dev_labels, dev_preds, average='macro'))\n",
        "  progress.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvavBKQEjbmn"
      },
      "source": [
        "## Your Model(s)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEUo_Thhjbmw"
      },
      "source": [
        "# ------------------\n",
        "# Put your implementation here (Multi Cell)    \n",
        "# ------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVSJRMWNjbmx"
      },
      "source": [
        "## Submit/Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pd2-4ZSjbmy",
        "outputId": "96d20e55-d1ce-4df7-bba6-0155c374cf96"
      },
      "source": [
        "test_labels, test_preds = predict_dataset(model, pos_test)\n",
        "macro_f1 = f1_score(test_labels, test_preds, average='macro')\n",
        "print(f'Macro F1-score on test set: {macro_f1*100:.1f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Macro F1-score on test set: 81.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSd5RLp71wfa"
      },
      "source": [
        "# SQuAD (Question Answering)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnLM4ni93UtT"
      },
      "source": [
        "**Question Answering (QA)** is the task of answering a question(source:nlpprogress :D  )! Most current QA datasets frame the task as reading comprehension where the question is about a paragraph or document and the answer often is a span in the document.\n",
        "\n",
        "The **Stanford Question Answering Dataset (SQuAD)** is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles. The answer to every question is a segment of text (a span) from the corresponding reading passage. \n",
        "\n",
        "To make it easier, we just use the questions with single word answers in this assignment. Take a look at [here](https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/) for more information on SQuAD. You can also read [this paper](https://www.aclweb.org/anthology/K17-1028/) to get a clue on how to tackle the problem wihtout RNNs.\n",
        "\n",
        "## Technical Notes:\n",
        "\n",
        "* The final expected output for our simplified task is the index of answer token in the passage (or the probability of each token being the correct answer). So the task is token based and the tokenization should be done on our side to make test results comparable in kaggle. \n",
        "\n",
        "* Our baseline uses glove embeddings and also its vocab (mapping tokens to ids) to create input tensors. If you want to change that, pass your version of `transform` function (other than our `convert_to_ids`) to `SquadDataset` class.\n",
        "\n",
        "* You can use any data for model training, except SQuAD 1.1 dev set which is considered as test set. And that's because the official test set of SQuAD is not publicly available.\n",
        "\n",
        "* Your model should be compatible with our `predict_dataset` function which returns predictions of model for all tokens in a dataset with shape `(NUM_EXAMPLES, MAX_PASSAGE_LENGTH)`. Or you can implement your own version of `predict_dataset` which returns that output without shuffling data.\n",
        "\n",
        "* <b><font color='red'>After local evaluation, submit (upload) your results to [this competition](https://www.kaggle.com/t/726281a9a5a34e6586c58790f6ebbe26) and compete with your classmates.</font></b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sGSZFKQj92X"
      },
      "source": [
        "## Our Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZITaNrEej92e",
        "cellView": "form"
      },
      "source": [
        "#@title Load GloVe embeddings\n",
        "\n",
        "EMBEDDING_DIM = 100 #@param {type:\"integer\"}\n",
        "glove = torchtext.vocab.GloVe(name='6B', dim=EMBEDDING_DIM)\n",
        "\n",
        "word2id = glove.stoi\n",
        "PAD_TOKEN_ID = len(word2id)\n",
        "word2id['<unk>'] = len(word2id)\n",
        "UNK_TOKEN_ID = len(word2id)\n",
        "word2id['<pad>'] = len(word2id)\n",
        "\n",
        "def convert_to_ids(tokens, pad=True, truncate=True, maxlen=32):\n",
        "  ids = [word2id[token] if token in word2id else UNK_TOKEN_ID for token in tokens]\n",
        "  if pad:\n",
        "   ids = ids + [PAD_TOKEN_ID] * (maxlen-len(ids))\n",
        "  if truncate:\n",
        "   ids = ids[:maxlen]\n",
        "  return ids\n",
        "\n",
        "clear_output()\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ug-tBp_Fj92g",
        "cellView": "form"
      },
      "source": [
        "#@title Load dataset\n",
        "\n",
        "BATCH_SIZE = 128 #@param {type:\"integer\"}\n",
        "MAX_QUESTION_LEN = 24 #@param {type:\"integer\"}\n",
        "MAX_PASSAGE_LEN = 256 #@param {type:\"integer\"}\n",
        "tokenizer = spacy.load('en')\n",
        "\n",
        "class SquadDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, split_name='train', transform=convert_to_ids,\n",
        "               max_question_len=24, max_passage_len=256):\n",
        "    super().__init__()\n",
        "\n",
        "    raw_dataset = torchtext.datasets.SQuAD1(split=split_name)\n",
        "\n",
        "    self.max_question_len = max_question_len\n",
        "    self.max_passage_len = max_passage_len\n",
        "    self.transform = transform\n",
        "    self.qa_pairs = []\n",
        "\n",
        "    for passage, question, ans_texts, ans_starts in tqdm(raw_dataset, desc='TOKENIZING'):\n",
        "      \n",
        "      answer_start = -1\n",
        "\n",
        "      # check if the question has a single token answer\n",
        "      for ans_text, ans_start in zip(ans_texts, ans_starts):\n",
        "        if len(tokenizer(ans_text, disable=['parser','tagger','ner'])) == 1:\n",
        "          answer_start = ans_start\n",
        "          break\n",
        "      else:\n",
        "        continue\n",
        "\n",
        "      passage_tokens = tokenizer(passage.lower(), disable=['parser','tagger','ner'])\n",
        "      p_tokens = [token.text for token in passage_tokens]\n",
        "      ans_idx = -1\n",
        "\n",
        "      # find index of answer token\n",
        "      for i, token in enumerate(passage_tokens):\n",
        "        if token.idx == answer_start and token.idx < self.max_passage_len:\n",
        "          ans_idx = i\n",
        "          break\n",
        "      else:\n",
        "        continue\n",
        "\n",
        "      q_tokens = [token.text for token in tokenizer(question.lower(), disable=['parser','tagger','ner'])]\n",
        "      self.qa_pairs.append((p_tokens, q_tokens, ans_idx))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.qa_pairs)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    p_tokens, q_tokens, ans_idx = self.qa_pairs[index]\n",
        "    p_ids = self.transform(p_tokens, maxlen=self.max_passage_len) \n",
        "    q_ids = self.transform(q_tokens, maxlen=self.max_question_len)\n",
        "\n",
        "    return (torch.tensor(p_ids),\n",
        "            torch.tensor(q_ids),\n",
        "            torch.tensor(ans_idx))\n",
        "   \n",
        "squad_train = SquadDataset(split_name='train',\n",
        "                           max_question_len=MAX_QUESTION_LEN,\n",
        "                           max_passage_len=MAX_PASSAGE_LEN)\n",
        "dev_size = len(squad_train) // 10\n",
        "train_size = len(squad_train) - dev_size\n",
        "\n",
        "squad_train, squad_dev = torch.utils.data.random_split(squad_train, [train_size, dev_size])\n",
        "\n",
        "squad_test = SquadDataset(split_name='dev',\n",
        "                          max_question_len=MAX_QUESTION_LEN,\n",
        "                          max_passage_len=MAX_PASSAGE_LEN)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(squad_train,\n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           shuffle=True,\n",
        "                                           pin_memory=True)\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-YupKHrFpw7",
        "cellView": "form"
      },
      "source": [
        "#@title Define baseline model\n",
        "\n",
        "class SquadBaseline(torch.nn.Module):\n",
        "  def __init__(self, word_embeddings):\n",
        "    super().__init__()\n",
        "\n",
        "    num_units = word_embeddings.dim\n",
        "\n",
        "    self.embedding = torch.nn.Embedding(len(word2id), word_embeddings.dim, padding_idx=PAD_TOKEN_ID)\n",
        "    self.embedding.weight.data.copy_(torch.cat([\n",
        "        word_embeddings.vectors,\n",
        "        torch.rand_like(word_embeddings.vectors[:1]),  # unk\n",
        "        torch.zeros_like(word_embeddings.vectors[:1])  # pad\n",
        "      ], dim=0))\n",
        "\n",
        "    self.p_linear = torch.nn.Linear(num_units, num_units)\n",
        "    self.q_linear = torch.nn.Linear(num_units, num_units)\n",
        "\n",
        "    self.classifier = torch.nn.Linear(num_units, 1)\n",
        "  \n",
        "  def forward(self, p_ids, q_ids):\n",
        "    p_embs = self.embedding(p_ids)\n",
        "    q_embs = self.embedding(q_ids)\n",
        "\n",
        "    p_features = torch.nn.functional.relu(self.p_linear(p_embs))\n",
        "    q_features = torch.nn.functional.relu(self.q_linear(q_embs))\n",
        "\n",
        "    q_reduced = q_features.mean(dim=1).unsqueeze(1)\n",
        "    merged = q_reduced.repeat(1, p_features.shape[1], 1) - p_features\n",
        "    logits = self.classifier(merged)\n",
        "    return logits.squeeze(-1)\n",
        "\n",
        "model = SquadBaseline(glove).cuda()\n",
        "\n",
        "for p in model.embedding.parameters():\n",
        "  p.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OeXA5JOOnb_"
      },
      "source": [
        "# @title Get predictions on dataset\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_dataset(model, dataset):\n",
        "  data_loader = torch.utils.data.DataLoader(dataset,\n",
        "                                            batch_size=BATCH_SIZE,\n",
        "                                            shuffle=False)\n",
        "  outputs, labels = [], []\n",
        "  \n",
        "  for p_ids, q_ids, indexes in data_loader:\n",
        "    logits = model(p_ids.cuda(), q_ids.cuda())\n",
        "    outputs.append(logits)\n",
        "    labels.append(indexes)\n",
        "\n",
        "  return (torch.cat(labels, dim=0).cpu().numpy(),\n",
        "          torch.cat(outputs, dim=0).cpu().numpy())\n",
        "\n",
        "# labels, outputs = predict_dataset(model, squad_dev)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ-PyuDQa3sL",
        "cellView": "form"
      },
      "source": [
        "#@title Training loop\n",
        "EPOCHS =    10#@param {type: \"integer\"}\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  progress = tqdm(train_loader, desc=f'EPOCH {epoch+1}')\n",
        "  \n",
        "  train_losses, train_corrects, train_total = [], 0, 0\n",
        "  for p_ids, q_ids, indexes in progress:\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    logits = model(p_ids.cuda(), q_ids.cuda())\n",
        "    loss = criterion(logits, indexes.cuda())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    preds = logits.argmax(dim=-1)\n",
        "    train_corrects += (preds == indexes.cuda()).int().sum().item()\n",
        "    train_total += p_ids.shape[0]\n",
        "    progress.set_postfix(loss=loss.item())\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "  progress.set_postfix(train_loss=sum(train_losses)/len(train_losses))\n",
        "  \n",
        "  labels, outputs = predict_dataset(model, squad_dev)\n",
        "\n",
        "  progress.set_postfix(train_loss=sum(train_losses)/len(train_losses),\n",
        "                       train_acc=train_corrects/train_total,\n",
        "                       val_acc=top_k_accuracy_score(labels, outputs, labels=list(range(MAX_PASSAGE_LEN)), k=1),\n",
        "                       top_5_val_acc=top_k_accuracy_score(labels, outputs, labels=list(range(MAX_PASSAGE_LEN)), k=5))\n",
        "  progress.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_Wz882utjVl"
      },
      "source": [
        "## Your Model(s)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylD5oUfetjVn"
      },
      "source": [
        "# ------------------\n",
        "# Put your implementation here (Multi Cell)    \n",
        "# ------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrSoppGJtjVo"
      },
      "source": [
        "## Submit/Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g596f-HetjVp",
        "cellView": "form"
      },
      "source": [
        "#@title Evaluation\n",
        "test_labels, test_preds = predict_dataset(model, squad_test)\n",
        "accuracy = top_k_accuracy_score(test_labels, test_preds, labels=list(range(MAX_PASSAGE_LEN)), k=1)\n",
        "accuracy_5 = top_k_accuracy_score(test_labels, test_preds, labels=list(range(MAX_PASSAGE_LEN)), k=5)\n",
        "\n",
        "print(f'Accuracy on test set: {accuracy*100:.2f}')\n",
        "print(f'Top-5 Accuracy on test set: {accuracy_5*100:.2f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "jNr7w4L259Tg"
      },
      "source": [
        "# @title Make kaggle submission file\n",
        "from google.colab import files\n",
        "\n",
        "test_preds = np.argmax(test_preds, axis=-1)\n",
        "\n",
        "with open('squad_submission.csv', 'w') as f:\n",
        "  S = 'id,label\\n'\n",
        "  for i, label in enumerate(test_preds):\n",
        "    S += f'{i},{label}\\n'\n",
        "  f.write(S[:-1])\n",
        "\n",
        "files.download('squad_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWRra63i2oFS"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQ6iRsAn2rlE"
      },
      "source": [
        "Congratulations! You finished the assignment & you're ready to submit your work. Please follow the instructions:\n",
        "\n",
        "1. Check and review your answers. Make sure all of the cell outputs are what you want. \n",
        "2. Select File > Save.\n",
        "3. **Fill your information** & run the cell bellow.\n",
        "4. Run **Make Submission** cell, It may take several minutes and it may ask you for your credential.\n",
        "5. Run **Download Submission** cell to obtain your submission as a zip file.\n",
        "6. Grab the downloaded file (`nlp_asg02__xx__xx.zip`) and hand it over in microsoft teams."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lL9OYI1C1wRq"
      },
      "source": [
        "## Fill your information (Run the cell)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ra5wTxj62CWc"
      },
      "source": [
        "#@title Enter your information & \"RUN the cell!!\" { run: \"auto\" }\n",
        "student_id = \"\" #@param {type:\"string\"}\n",
        "student_name = \"\" #@param {type:\"string\"}\n",
        "\n",
        "print(\"your student id:\", student_id)\n",
        "print(\"your name:\", student_name)\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "ASSIGNMENT_PATH = Path('asg02')\n",
        "ASSIGNMENT_PATH.mkdir(parents=True, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFYJJJhh3kpj"
      },
      "source": [
        "## Make Submission (Run the cell)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBQc5tBQ2sFJ",
        "cellView": "form"
      },
      "source": [
        "#@title Make submission\n",
        "! pip install -U --quiet PyDrive > /dev/null\n",
        "! pip install -U --quiet jdatetime > /dev/null\n",
        "\n",
        "# ! wget -q https://github.com/github/hub/releases/download/v2.10.0/hub-linux-amd64-2.10.0.tgz \n",
        "\n",
        "\n",
        "import os\n",
        "import time\n",
        "import yaml\n",
        "import json\n",
        "import jdatetime\n",
        "\n",
        "from google.colab import files\n",
        "from IPython.display import Javascript\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "asg_name = 'NLP_Assignment_2'\n",
        "script_save = '''\n",
        "require([\"base/js/namespace\"],function(Jupyter) {\n",
        "    Jupyter.notebook.save_checkpoint();\n",
        "});\n",
        "'''\n",
        "# repo_name = 'iust-deep-learning-assignments'\n",
        "submission_file_name = 'nlp_asg02__%s__%s.zip'%(student_id, student_name.lower().replace(' ',  '_'))\n",
        "\n",
        "sub_info = {\n",
        "    'student_id': student_id,\n",
        "    'student_name': student_name, \n",
        "    'dateime': str(jdatetime.date.today()),\n",
        "    'asg_name': asg_name\n",
        "}\n",
        "json.dump(sub_info, open('info.json', 'w'))\n",
        "\n",
        "Javascript(script_save)\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "file_id = drive.ListFile({'q':\"title='%s.ipynb'\"%asg_name}).GetList()[0]['id']\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('%s.ipynb'%asg_name) \n",
        "\n",
        "! jupyter nbconvert --to script \"$asg_name\".ipynb > /dev/null\n",
        "! jupyter nbconvert --to html \"$asg_name\".ipynb > /dev/null\n",
        "! zip \"$submission_file_name\" \"$asg_name\".ipynb \"$asg_name\".html \"$asg_name\".txt info.json > /dev/null\n",
        "\n",
        "print(\"##########################################\")\n",
        "print(\"Done! Submisson created, Please download using the bellow cell!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3n3JS51xqUo"
      },
      "source": [
        "drive.ListFile({'q':\"title='%s.ipynb'\"%asg_name}).GetList()[0]['id']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RclPk2VM30Qa"
      },
      "source": [
        "files.download(submission_file_name)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}