---
hide_hero: true
layout: page
hide_hero: true
show_sidebar: false
---

# Course Schedule

## Esfand 99

| Session 	| Date	| Topic |
|------|------|------|
| 1 | 3 Esfand | Introduction	| 
| 2 | 5 Esfand | Word representations (Distributional semantics, co-occurrence matrix, dimensionality reduction and SVD, language models)	<br> Readings: [[cs224n-1]](http://web.stanford.edu/class/cs224n/slides/cs224n-2021-lecture01-wordvecs1.pdf)[[cs224n-1-notes]](http://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes01-wordvecs1.pdf)| 
| 3 | 10 Esfand | Word embeddings	(Word2vec, GloVe) <br> Readings: [[cs224n-1]](http://web.stanford.edu/class/cs224n/slides/cs224n-2021-lecture01-wordvecs1.pdf)[[cs224n-1-notes]](http://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes01-wordvecs1.pdf)| 
| 4 | 12 Esfand | Word embeddings (Evaluation, cross-lingual space, ambiguity and sense embeddings)	<br> Readings: [[cs224n-2]](http://web.stanford.edu/class/cs224n/slides/cs224n-2021-lecture02-wordvecs2.pdf) [[cs224n-2-notes]]([[cs224n-1-notes]](http://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes01-wordvecs1.pdf))| 
| 5 | 17 Esfand | Word embeddings (Sub-word embeddings, retrofitting, debiasing) <br> Readings: [[nn4nlp2021]](http://www.phontron.com/class/nn4nlp2021/schedule/wordemb.html)| 
| 6 | 19 Esfand | Text classification and regression	<br> Readings: [[info256-5]](https://people.ischool.berkeley.edu/~dbamman/anlp19_slides/5_classification.pdf)[[info256-6]](https://people.ischool.berkeley.edu/~dbamman/anlp19_slides/6_regression.pdf)| 
| 7 | 24 Esfand | Language modeling	(n-gram, probability computation, back-off interpolation, sparsity and smoothing, feedforward NN for LM) <br> Readings: [[cs224n-5]](http://web.stanford.edu/class/cs224n/slides/cs224n-2021-lecture05-rnnlm.pdf)[[Voita-LM]](https://lena-voita.github.io/nlp_course/language_modeling.html) |
| 8 | 26 Esfand | Language modeling with RNNs	(backprop through time, text generation, perplexity, text generation, sampling with temprature) <br> Readings: [[cs224n-5]](http://web.stanford.edu/class/cs224n/slides/cs224n-2021-lecture05-rnnlm.pdf)[[Voita-LM]](https://lena-voita.github.io/nlp_course/language_modeling.html) |

## Farvardin 00

| Session 	| Date	| Topic |
|------|------|------|
| 9 | 15 Farvardin | Vanishing/exploding gradients and fancy RNNs (LSTMs, bidirectional and stacked RNNs)	 <br> Readings: [[cs224n-6]](http://web.stanford.edu/class/cs224n/slides/cs224n-2021-lecture06-fancy-rnn.pdf) [[cs224n-6-notes]](http://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes05-LM_RNN.pdf) |
| 10 | 17 Farvardin | Machine Translation (SMT, NMT, seq2seq models, beam-search decoding, evaluation) and attention mechanism <br> Readings: [[cs224n-7]](http://web.stanford.edu/class/cs224n/slides/cs224n-2021-lecture07-nmt.pdf) [[cs224n-7-notes]](http://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes06-NMT_seq2seq_attention.pdf) |
| 11 | 22 Farvardin | *Paper discussion on RNNs* |
| 12 | 24 Farvardin | Word senses and contextualization |
| 13 | 29 Farvardin | **Progress Report I** |
| 14 | 31 Farvardin | Transformers |

## Ordibehesht 00

| Session 	| Date	| Topic |
|------|------|------|
| 15 | 5 Ordibehesht | More about Transformers and Pretraining  |
| 16 | 7 Ordibehesht | *Paper discussion on Transformers* |
| 17 | 12 Ordibehesht | \*Isotropicity of Semantic Spaces (Rajaee) |
| 18 | 19 Ordibehesht | Question Answering |
| 19 | 21 Ordibehesht | Neural Language Generation |
| 20 | 26 Ordibehesht | **Progress Report II** |
| 21 | 28 Ordibehesht | \*LM-based Word Sense Disambiguation (Rezaee) |

## Khordad 00

| Session 	| Date	| Topic |
|------|------|------|
| 22 | 2 Khordad | \*Interpretability (Modaressi & Mohebbi) |
| 23 | 4 Khordad | \*Dialogue (Pourdabiri) |
| 24 | 9 Khordad | Integrating knowledge in language models |
| 25 | 11 Khordad | \*Zero-shot applictions of Cloze test (Tabasi) |
| 26 | 16 Khordad | *Paper discussion* |
| 27 | 18 Khordad | **Progress Report III** |



